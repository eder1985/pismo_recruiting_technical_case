{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yXufyZSDnPEX",
        "VZwsr57lwPgq",
        "eUazdCEmu_sp",
        "yTVjYqeRuxWn"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eder1985/pismo_recruiting_technical_case/blob/main/work/notebooks/Colab_Pismo_Recruiting_Technical_Case.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iox_ufgbqDXa"
      },
      "source": [
        "<h1><center>Pismo Recruiting Technical Case</center></h1>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFnYZltvqLgt"
      },
      "source": [
        "## Objective\n",
        "The objective of this notebook is to:\n",
        "><li>Give a proper understanding about the different PySpark functions available. </li>\n",
        "><li>A short introduction to Google Colab, as that is the platform on which this notebook is written on. </li>\n",
        "\n",
        "Once you complete this notebook, you should be able to write pyspark programs in an efficent way. The ideal way to use this is by going through the examples given and then trying them on Colab. At the end there are a few hands on questions which you can use to evaluate yourself."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Pre-requisites"
      ],
      "metadata": {
        "id": "JCAgeiPdnkA2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd6t0uFzuR4X"
      },
      "source": [
        "### Installing Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6apGVff5h4ca"
      },
      "source": [
        "Install Dependencies:\n",
        "\n",
        "\n",
        "1.   Java 8\n",
        "2.   Apache Spark with hadoop and\n",
        "3.   Findspark (used to locate the spark in the system)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt7ZS1_wGgjn"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3x0ZRLxjMVr"
      },
      "source": [
        "Set Environment Variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdOOq4twHN1K"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ACYMwhgHTYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9346c054-ab0c-4559-b4b8-5867f1c8e071"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  spark-3.1.1-bin-hadoop3.2\tspark-3.1.1-bin-hadoop3.2.tgz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR1zLBk1998Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "720854fd-fe35-47e2-9513-f70c1e311293"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ae568a85480>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://3b7248297f6f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXufyZSDnPEX"
      },
      "source": [
        "## 2. Generate Fake Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing libs"
      ],
      "metadata": {
        "id": "lFjhBqLzopOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKtqR1_EotAp",
        "outputId": "021ac0e1-8a83-486e-ac91-d77c06c4e698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13c17833-ae7d-421d-a202-67f7bd6e15da"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "b09f623a-a917-40b2-935e-9f3418eeb5d0"
      },
      "outputs": [],
      "source": [
        "from faker import Faker\n",
        "from faker.providers import BaseProvider\n",
        "from datetime import datetime\n",
        "from json import dumps\n",
        "import pandas as pd\n",
        "import random\n",
        "import collections\n",
        "import glob\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1271033-3194-4676-b653-7329269465bd"
      },
      "source": [
        "### Generating fake `event_id`: random UUIDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbb2e109-25d6-4b7d-9a2d-b27defaf30c7",
        "outputId": "d122deb3-7fff-48c6-bae2-4b5cbde058a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8dfb2a88-0b16-4681-ab20-27edfe0be021\n"
          ]
        }
      ],
      "source": [
        "fake = Faker()\n",
        "Faker.seed(random.randrange(0, 99999999999999999999, 1))\n",
        "fake_event_id = fake.uuid4()\n",
        "print(fake_event_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "20155f18-3a4c-4ffc-ba04-cb2e68d1de4c"
      },
      "source": [
        "### Generating fake `timestamp`: random timestamps with values until 3 years ago"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05c17a17",
        "outputId": "eb2b8376-c631-46cb-98c9-704752fdc876",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-15T05:54:52\n"
          ]
        }
      ],
      "source": [
        "fake_timestamp = datetime.strftime(fake.date_time_between(start_date='-3y', end_date='now'),\"%Y-%m-%dT%H:%M:%S\")\n",
        "print(fake_timestamp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "cf00e3d1-b80f-4f2b-80cc-1d9d38aedb62"
      },
      "source": [
        "### Generating fake `domain`: random values based on valid grade names list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "6f69aa9d-0b6b-4155-9d95-ffe79f430eb2",
        "outputId": "cc4002ac-9fa1-496b-b2a0-5dd32f6e1b8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "account\n"
          ]
        }
      ],
      "source": [
        "class ProjectDomainProvider(BaseProvider):\n",
        "    def project_domain_name(self):\n",
        "        list_project_domain_names = ['account','transaction']\n",
        "        return random.choice(list_project_domain_names)\n",
        "\n",
        "fake.add_provider(ProjectDomainProvider)\n",
        "\n",
        "fake_project_domain_name = fake.project_domain_name()\n",
        "print(fake_project_domain_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "89e61378-9300-4c0e-b2a1-d548f3658d92"
      },
      "source": [
        "### Generating fake `status`: random values based on list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "38144fc2-3bdf-4cd2-aaba-f7387dc2749a",
        "outputId": "fca45751-d7a0-4c64-da14-8c204e24a33c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUSPENDED\n"
          ]
        }
      ],
      "source": [
        "class StatusTypeProvider(BaseProvider):\n",
        "    def status_type(self):\n",
        "        list_status_types = ['ACTIVE','INACTIVE','SUSPENDED','BLOCKED', 'DELETED']\n",
        "        return random.choice(list_status_types)\n",
        "\n",
        "fake.add_provider(StatusTypeProvider)\n",
        "\n",
        "fake_status_type = fake.status_type()\n",
        "print(fake_status_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daf470cd"
      },
      "source": [
        "### Generating custom fake `uuid`: random values based on list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "bc529de4"
      },
      "outputs": [],
      "source": [
        "class CustomUUIDProvider(BaseProvider):\n",
        "    def custom_uuid(self):\n",
        "        list_uuids = [\n",
        "            '1a1a1a1a-1a1a-1a1a-1a1a-1a1a1a1a1a1a',\n",
        "            '2b2b2b2b-2b2b-2b2b-2b2b-2b2b2b2b2b2b'\n",
        "            ]\n",
        "        return random.choice(list_uuids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b71c70e2-9a78-4595-84fd-0c733c652e23"
      },
      "source": [
        "### Defining `write_fake_data` and `read_fake_data` functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "8aeda55c"
      },
      "outputs": [],
      "source": [
        "def write_fake_data(fake, length, destination_path, unique_uuid = True):\n",
        "\n",
        "    database = []\n",
        "    current_time = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "    filename = 'fake_events_'+current_time\n",
        "\n",
        "    for x in range(length):\n",
        "        uuid = fake.uuid4() if unique_uuid else fake.custom_uuid()\n",
        "        project_domain_name = fake.project_domain_name()\n",
        "        event_type = project_domain_name + \"-status-change\"\n",
        "\n",
        "        database.append(collections.OrderedDict([\n",
        "            ('event_id', uuid),\n",
        "            ('timestamp', datetime.strftime(fake.date_time_between(start_date='-3y', end_date='now'),\"%Y-%m-%dT%H:%M:%S\")),\n",
        "            ('domain', project_domain_name),\n",
        "            ('event_type', event_type),\n",
        "            ('data', collections.OrderedDict([\n",
        "                ('id', fake.random_number(digits=6)),\n",
        "                ('old_status', fake.status_type()),\n",
        "                ('new_status', fake.status_type()),\n",
        "                ('reason', fake.sentence(nb_words=5))\n",
        "            ]))\n",
        "        ]))\n",
        "\n",
        "    with open('%s%s.json' % (destination_path, filename), 'w') as output:\n",
        "        output.write(dumps(database, indent=4, sort_keys=False, default=str))\n",
        "\n",
        "    print(\"Done.\")\n",
        "\n",
        "def read_fake_data(json_filepath):\n",
        "    json_files = [os.path.normpath(i) for i in glob.glob(json_filepath)]\n",
        "    df = pd.concat([pd.read_json(f) for f in json_files])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7768a0c8"
      },
      "source": [
        "### Writing and reading fake data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "82a2a3c9"
      },
      "outputs": [],
      "source": [
        "def run(unique_uuid = True):\n",
        "    fake = Faker()\n",
        "    Faker.seed(random.randrange(0, 99999999999999999999, 1))\n",
        "    fake.add_provider(ProjectDomainProvider)\n",
        "    fake.add_provider(StatusTypeProvider)\n",
        "    fake.add_provider(CustomUUIDProvider)\n",
        "\n",
        "    length = 10\n",
        "    destination_path = 'sample_data/raw/events/'\n",
        "    write_fake_data(fake, length, destination_path,unique_uuid)\n",
        "\n",
        "    json_filepath = destination_path+'*.json'\n",
        "    fake_data = read_fake_data(json_filepath)\n",
        "    print(fake_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "2a05df7b",
        "outputId": "bc4de350-95e7-40c2-e102-1f7e049b41b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "                               event_id           timestamp       domain  \\\n",
            "0  5be1ef0a-a7ba-42bc-8274-c180eed6f21b 2022-10-10 04:41:34  transaction   \n",
            "1  f8bc5b80-5d48-4798-a218-aa5995e408c8 2021-09-20 08:51:27  transaction   \n",
            "2  e9386cae-9588-4194-a07e-c650c803e809 2022-11-11 22:26:28      account   \n",
            "3  436361fe-68a0-44a7-99ff-1eadc36436fd 2021-07-19 01:23:34      account   \n",
            "4  0cf8af3b-307c-4469-8a2e-60446f57453f 2022-03-23 13:42:49      account   \n",
            "5  16610c50-b322-4239-a52f-9b0045fd60c8 2022-08-17 13:55:55  transaction   \n",
            "6  89302a03-8bb3-4bf7-be6f-c2b0c6ab7412 2022-08-03 21:24:01      account   \n",
            "7  fe59189d-43ab-46d8-920e-07426a0b093d 2022-11-16 05:16:00  transaction   \n",
            "8  af3775cc-f381-40ce-8587-0c51eeaacb20 2021-11-01 20:19:33  transaction   \n",
            "9  637c7baa-29f3-450d-b837-538e15996ccc 2023-05-23 15:48:58  transaction   \n",
            "\n",
            "                  event_type  \\\n",
            "0  transaction-status-change   \n",
            "1  transaction-status-change   \n",
            "2      account-status-change   \n",
            "3      account-status-change   \n",
            "4      account-status-change   \n",
            "5  transaction-status-change   \n",
            "6      account-status-change   \n",
            "7  transaction-status-change   \n",
            "8  transaction-status-change   \n",
            "9  transaction-status-change   \n",
            "\n",
            "                                                data  \n",
            "0  {'id': 575493, 'old_status': 'DELETED', 'new_s...  \n",
            "1  {'id': 36211, 'old_status': 'SUSPENDED', 'new_...  \n",
            "2  {'id': 627429, 'old_status': 'INACTIVE', 'new_...  \n",
            "3  {'id': 45467, 'old_status': 'SUSPENDED', 'new_...  \n",
            "4  {'id': 143484, 'old_status': 'BLOCKED', 'new_s...  \n",
            "5  {'id': 831135, 'old_status': 'ACTIVE', 'new_st...  \n",
            "6  {'id': 131841, 'old_status': 'SUSPENDED', 'new...  \n",
            "7  {'id': 715598, 'old_status': 'INACTIVE', 'new_...  \n",
            "8  {'id': 428455, 'old_status': 'SUSPENDED', 'new...  \n",
            "9  {'id': 186381, 'old_status': 'SUSPENDED', 'new...  \n"
          ]
        }
      ],
      "source": [
        "run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "64906f56",
        "outputId": "bf6064ea-7a87-4236-cc16-c7d4350b86b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "                               event_id           timestamp       domain  \\\n",
            "0  2b2b2b2b-2b2b-2b2b-2b2b-2b2b2b2b2b2b 2021-06-16 03:01:17      account   \n",
            "1  1a1a1a1a-1a1a-1a1a-1a1a-1a1a1a1a1a1a 2021-04-03 10:30:42  transaction   \n",
            "2  1a1a1a1a-1a1a-1a1a-1a1a-1a1a1a1a1a1a 2023-04-27 05:52:51      account   \n",
            "3  2b2b2b2b-2b2b-2b2b-2b2b-2b2b2b2b2b2b 2023-06-23 12:42:11      account   \n",
            "4  2b2b2b2b-2b2b-2b2b-2b2b-2b2b2b2b2b2b 2021-06-10 01:03:22      account   \n",
            "5  1a1a1a1a-1a1a-1a1a-1a1a-1a1a1a1a1a1a 2021-09-08 20:55:51  transaction   \n",
            "6  1a1a1a1a-1a1a-1a1a-1a1a-1a1a1a1a1a1a 2021-11-01 20:55:19      account   \n",
            "7  2b2b2b2b-2b2b-2b2b-2b2b-2b2b2b2b2b2b 2022-07-24 01:30:51      account   \n",
            "8  2b2b2b2b-2b2b-2b2b-2b2b-2b2b2b2b2b2b 2023-01-23 23:55:20      account   \n",
            "9  1a1a1a1a-1a1a-1a1a-1a1a-1a1a1a1a1a1a 2022-06-22 18:52:09      account   \n",
            "0  5be1ef0a-a7ba-42bc-8274-c180eed6f21b 2022-10-10 04:41:34  transaction   \n",
            "1  f8bc5b80-5d48-4798-a218-aa5995e408c8 2021-09-20 08:51:27  transaction   \n",
            "2  e9386cae-9588-4194-a07e-c650c803e809 2022-11-11 22:26:28      account   \n",
            "3  436361fe-68a0-44a7-99ff-1eadc36436fd 2021-07-19 01:23:34      account   \n",
            "4  0cf8af3b-307c-4469-8a2e-60446f57453f 2022-03-23 13:42:49      account   \n",
            "5  16610c50-b322-4239-a52f-9b0045fd60c8 2022-08-17 13:55:55  transaction   \n",
            "6  89302a03-8bb3-4bf7-be6f-c2b0c6ab7412 2022-08-03 21:24:01      account   \n",
            "7  fe59189d-43ab-46d8-920e-07426a0b093d 2022-11-16 05:16:00  transaction   \n",
            "8  af3775cc-f381-40ce-8587-0c51eeaacb20 2021-11-01 20:19:33  transaction   \n",
            "9  637c7baa-29f3-450d-b837-538e15996ccc 2023-05-23 15:48:58  transaction   \n",
            "\n",
            "                  event_type  \\\n",
            "0      account-status-change   \n",
            "1  transaction-status-change   \n",
            "2      account-status-change   \n",
            "3      account-status-change   \n",
            "4      account-status-change   \n",
            "5  transaction-status-change   \n",
            "6      account-status-change   \n",
            "7      account-status-change   \n",
            "8      account-status-change   \n",
            "9      account-status-change   \n",
            "0  transaction-status-change   \n",
            "1  transaction-status-change   \n",
            "2      account-status-change   \n",
            "3      account-status-change   \n",
            "4      account-status-change   \n",
            "5  transaction-status-change   \n",
            "6      account-status-change   \n",
            "7  transaction-status-change   \n",
            "8  transaction-status-change   \n",
            "9  transaction-status-change   \n",
            "\n",
            "                                                data  \n",
            "0  {'id': 38239, 'old_status': 'BLOCKED', 'new_st...  \n",
            "1  {'id': 34640, 'old_status': 'SUSPENDED', 'new_...  \n",
            "2  {'id': 517307, 'old_status': 'SUSPENDED', 'new...  \n",
            "3  {'id': 640554, 'old_status': 'BLOCKED', 'new_s...  \n",
            "4  {'id': 353054, 'old_status': 'SUSPENDED', 'new...  \n",
            "5  {'id': 384121, 'old_status': 'DELETED', 'new_s...  \n",
            "6  {'id': 926732, 'old_status': 'BLOCKED', 'new_s...  \n",
            "7  {'id': 604668, 'old_status': 'BLOCKED', 'new_s...  \n",
            "8  {'id': 372876, 'old_status': 'DELETED', 'new_s...  \n",
            "9  {'id': 311978, 'old_status': 'INACTIVE', 'new_...  \n",
            "0  {'id': 575493, 'old_status': 'DELETED', 'new_s...  \n",
            "1  {'id': 36211, 'old_status': 'SUSPENDED', 'new_...  \n",
            "2  {'id': 627429, 'old_status': 'INACTIVE', 'new_...  \n",
            "3  {'id': 45467, 'old_status': 'SUSPENDED', 'new_...  \n",
            "4  {'id': 143484, 'old_status': 'BLOCKED', 'new_s...  \n",
            "5  {'id': 831135, 'old_status': 'ACTIVE', 'new_st...  \n",
            "6  {'id': 131841, 'old_status': 'SUSPENDED', 'new...  \n",
            "7  {'id': 715598, 'old_status': 'INACTIVE', 'new_...  \n",
            "8  {'id': 428455, 'old_status': 'SUSPENDED', 'new...  \n",
            "9  {'id': 186381, 'old_status': 'SUSPENDED', 'new...  \n"
          ]
        }
      ],
      "source": [
        "run(unique_uuid = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmIqq6xPK7m7"
      },
      "source": [
        "## 3. Exploring the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZwsr57lwPgq"
      },
      "source": [
        "### Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpq2jYvIMOJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "721b1e0f-265a-4a70-d508-98a19f1d1c9a"
      },
      "source": [
        "!ls sample_data/input -la"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 16\n",
            "drwxr-xr-x 2 root root 4096 Jul 25 20:06 .\n",
            "drwxr-xr-x 1 root root 4096 Jul 25 20:06 ..\n",
            "-rw-r--r-- 1 root root 3726 Jul 25 20:06 fake_events_20230725200641.json\n",
            "-rw-r--r-- 1 root root 3732 Jul 25 20:06 fake_events_20230725200645.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz6ALr5mMqZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13d6d36-dfe2-498d-ce3e-ff7510cc3bc1"
      },
      "source": [
        "raw_events = spark.read.option(\"multiline\",\"true\").json('sample_data/raw/events/')\n",
        "raw_events.show(5, truncate = False)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------+-----------+------------------------------------+-------------+-------------------+\n",
            "|data                                                         |domain     |event_id                            |event_type   |timestamp          |\n",
            "+-------------------------------------------------------------+-----------+------------------------------------+-------------+-------------------+\n",
            "|{799538, ACTIVE, INACTIVE, Meet discussion against language.}|account    |ccec286e-02ad-4148-9267-ea2e5c8b7113|status-change|2021-07-21T06:26:46|\n",
            "|{858312, BLOCKED, ACTIVE, Time idea soldier face ready.}     |transaction|2621940c-baad-478c-875c-74626489fdf4|status-change|2020-12-14T02:44:35|\n",
            "|{594079, SUSPENDED, BLOCKED, Near term break.}               |transaction|83944be2-c999-4efe-8db5-f76a21e46eb9|status-change|2023-05-01T18:11:33|\n",
            "|{286640, SUSPENDED, INACTIVE, South per well stand mother.}  |account    |adcae8a6-41d4-49e8-8fe0-0d524226850e|status-change|2020-08-19T05:23:19|\n",
            "|{788440, BLOCKED, INACTIVE, Fill effect choice blood.}       |account    |c8df2c53-2888-437d-b93c-b20f9b1062d5|status-change|2021-03-07T05:01:56|\n",
            "+-------------------------------------------------------------+-----------+------------------------------------+-------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lfS2DhHuhPl"
      },
      "source": [
        "### Dataframe Raw Schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCGTFlCWRPw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b329444-6c58-464e-a593-459d0e78a35d"
      },
      "source": [
        "raw_events.printSchema()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- data: struct (nullable = true)\n",
            " |    |-- id: long (nullable = true)\n",
            " |    |-- new_status: string (nullable = true)\n",
            " |    |-- old_status: string (nullable = true)\n",
            " |    |-- reason: string (nullable = true)\n",
            " |-- domain: string (nullable = true)\n",
            " |-- event_id: string (nullable = true)\n",
            " |-- event_type: string (nullable = true)\n",
            " |-- timestamp: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsD48rckdHPe"
      },
      "source": [
        "## DataFrame Operations on Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMlxdWfSY8ks"
      },
      "source": [
        "We will go over the following in this section:\n",
        "\n",
        "1.   Selecting Columns\n",
        "2.   Selecting Multiple Columns\n",
        "3.   Adding New Columns\n",
        "4.   Renaming Columns\n",
        "5.   Grouping By Columns\n",
        "6.   Removing Columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikGR5pDICTu7"
      },
      "source": [
        "<a id='selecting-columns'></a>\n",
        "### Selecting Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwIwi2rj_o"
      },
      "source": [
        "There are multiple ways to do a select in PySpark. You can find how they differ and how each below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge9-_ygideWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37bd7e10-1169-4243-fb5e-798cd980c423"
      },
      "source": [
        "# 1st method\n",
        "# Column name is case sensitive in this usage\n",
        "print(df.Car)\n",
        "print(\"*\"*20)\n",
        "df.select(df.Car).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column<'Car'>\n",
            "********************\n",
            "+--------------------------------+\n",
            "|Car                             |\n",
            "+--------------------------------+\n",
            "|Chevrolet Chevelle Malibu       |\n",
            "|Buick Skylark 320               |\n",
            "|Plymouth Satellite              |\n",
            "|AMC Rebel SST                   |\n",
            "|Ford Torino                     |\n",
            "|Ford Galaxie 500                |\n",
            "|Chevrolet Impala                |\n",
            "|Plymouth Fury iii               |\n",
            "|Pontiac Catalina                |\n",
            "|AMC Ambassador DPL              |\n",
            "|Citroen DS-21 Pallas            |\n",
            "|Chevrolet Chevelle Concours (sw)|\n",
            "|Ford Torino (sw)                |\n",
            "|Plymouth Satellite (sw)         |\n",
            "|AMC Rebel SST (sw)              |\n",
            "|Dodge Challenger SE             |\n",
            "|Plymouth 'Cuda 340              |\n",
            "|Ford Mustang Boss 302           |\n",
            "|Chevrolet Monte Carlo           |\n",
            "|Buick Estate Wagon (sw)         |\n",
            "+--------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxP1su8veNde"
      },
      "source": [
        "**NOTE:**\n",
        "\n",
        "> **We can't always use the dot notation because this will break when the column names have reserved names or attributes to the data frame class. Additionally, the column names are case sensitive in nature so we need to always make sure the column names have been changed to a paticular case before using it.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md5zaET8dsr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "534f2e91-1c8a-48c9-c666-8af90443e896"
      },
      "source": [
        "# 2nd method\n",
        "# Column name is case insensitive here\n",
        "print(df['car'])\n",
        "print(\"*\"*20)\n",
        "df.select(df['car']).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column<'car'>\n",
            "********************\n",
            "+--------------------------------+\n",
            "|car                             |\n",
            "+--------------------------------+\n",
            "|Chevrolet Chevelle Malibu       |\n",
            "|Buick Skylark 320               |\n",
            "|Plymouth Satellite              |\n",
            "|AMC Rebel SST                   |\n",
            "|Ford Torino                     |\n",
            "|Ford Galaxie 500                |\n",
            "|Chevrolet Impala                |\n",
            "|Plymouth Fury iii               |\n",
            "|Pontiac Catalina                |\n",
            "|AMC Ambassador DPL              |\n",
            "|Citroen DS-21 Pallas            |\n",
            "|Chevrolet Chevelle Concours (sw)|\n",
            "|Ford Torino (sw)                |\n",
            "|Plymouth Satellite (sw)         |\n",
            "|AMC Rebel SST (sw)              |\n",
            "|Dodge Challenger SE             |\n",
            "|Plymouth 'Cuda 340              |\n",
            "|Ford Mustang Boss 302           |\n",
            "|Chevrolet Monte Carlo           |\n",
            "|Buick Estate Wagon (sw)         |\n",
            "+--------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gkf14sHec9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a965002e-eb65-462d-fa1f-4959251216cd"
      },
      "source": [
        "# 3rd method\n",
        "# Column name is case insensitive here\n",
        "from pyspark.sql.functions import col\n",
        "df.select(col('car')).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------+\n",
            "|car                             |\n",
            "+--------------------------------+\n",
            "|Chevrolet Chevelle Malibu       |\n",
            "|Buick Skylark 320               |\n",
            "|Plymouth Satellite              |\n",
            "|AMC Rebel SST                   |\n",
            "|Ford Torino                     |\n",
            "|Ford Galaxie 500                |\n",
            "|Chevrolet Impala                |\n",
            "|Plymouth Fury iii               |\n",
            "|Pontiac Catalina                |\n",
            "|AMC Ambassador DPL              |\n",
            "|Citroen DS-21 Pallas            |\n",
            "|Chevrolet Chevelle Concours (sw)|\n",
            "|Ford Torino (sw)                |\n",
            "|Plymouth Satellite (sw)         |\n",
            "|AMC Rebel SST (sw)              |\n",
            "|Dodge Challenger SE             |\n",
            "|Plymouth 'Cuda 340              |\n",
            "|Ford Mustang Boss 302           |\n",
            "|Chevrolet Monte Carlo           |\n",
            "|Buick Estate Wagon (sw)         |\n",
            "+--------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6QsMfnNt3qF"
      },
      "source": [
        "<a id='selecting-multiple-columns'></a>\n",
        "### Selecting Multiple Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPjLMhZ6uAQR",
        "outputId": "920f8155-50f5-43ae-eb3d-2b9f6be7756e"
      },
      "source": [
        "# 1st method\n",
        "# Column name is case sensitive in this usage\n",
        "print(df.Car, df.Cylinders)\n",
        "print(\"*\"*40)\n",
        "df.select(df.Car, df.Cylinders).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column<'Car'> Column<'Cylinders'>\n",
            "****************************************\n",
            "+--------------------------------+---------+\n",
            "|Car                             |Cylinders|\n",
            "+--------------------------------+---------+\n",
            "|Chevrolet Chevelle Malibu       |8        |\n",
            "|Buick Skylark 320               |8        |\n",
            "|Plymouth Satellite              |8        |\n",
            "|AMC Rebel SST                   |8        |\n",
            "|Ford Torino                     |8        |\n",
            "|Ford Galaxie 500                |8        |\n",
            "|Chevrolet Impala                |8        |\n",
            "|Plymouth Fury iii               |8        |\n",
            "|Pontiac Catalina                |8        |\n",
            "|AMC Ambassador DPL              |8        |\n",
            "|Citroen DS-21 Pallas            |4        |\n",
            "|Chevrolet Chevelle Concours (sw)|8        |\n",
            "|Ford Torino (sw)                |8        |\n",
            "|Plymouth Satellite (sw)         |8        |\n",
            "|AMC Rebel SST (sw)              |8        |\n",
            "|Dodge Challenger SE             |8        |\n",
            "|Plymouth 'Cuda 340              |8        |\n",
            "|Ford Mustang Boss 302           |8        |\n",
            "|Chevrolet Monte Carlo           |8        |\n",
            "|Buick Estate Wagon (sw)         |8        |\n",
            "+--------------------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMRMUrv7uHWa",
        "outputId": "711ecef5-9f20-4106-b935-fb722ec14f72"
      },
      "source": [
        "# 2nd method\n",
        "# Column name is case insensitive in this usage\n",
        "print(df['car'],df['cylinders'])\n",
        "print(\"*\"*40)\n",
        "df.select(df['car'],df['cylinders']).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column<'car'> Column<'cylinders'>\n",
            "****************************************\n",
            "+--------------------------------+---------+\n",
            "|car                             |cylinders|\n",
            "+--------------------------------+---------+\n",
            "|Chevrolet Chevelle Malibu       |8        |\n",
            "|Buick Skylark 320               |8        |\n",
            "|Plymouth Satellite              |8        |\n",
            "|AMC Rebel SST                   |8        |\n",
            "|Ford Torino                     |8        |\n",
            "|Ford Galaxie 500                |8        |\n",
            "|Chevrolet Impala                |8        |\n",
            "|Plymouth Fury iii               |8        |\n",
            "|Pontiac Catalina                |8        |\n",
            "|AMC Ambassador DPL              |8        |\n",
            "|Citroen DS-21 Pallas            |4        |\n",
            "|Chevrolet Chevelle Concours (sw)|8        |\n",
            "|Ford Torino (sw)                |8        |\n",
            "|Plymouth Satellite (sw)         |8        |\n",
            "|AMC Rebel SST (sw)              |8        |\n",
            "|Dodge Challenger SE             |8        |\n",
            "|Plymouth 'Cuda 340              |8        |\n",
            "|Ford Mustang Boss 302           |8        |\n",
            "|Chevrolet Monte Carlo           |8        |\n",
            "|Buick Estate Wagon (sw)         |8        |\n",
            "+--------------------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgQ20-4GugjR",
        "outputId": "91f3f5e6-b90d-413b-ab7f-10efc81b77aa"
      },
      "source": [
        "# 3rd method\n",
        "# Column name is case insensitive in this usage\n",
        "from pyspark.sql.functions import col\n",
        "df.select(col('car'),col('cylinders')).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------+---------+\n",
            "|car                             |cylinders|\n",
            "+--------------------------------+---------+\n",
            "|Chevrolet Chevelle Malibu       |8        |\n",
            "|Buick Skylark 320               |8        |\n",
            "|Plymouth Satellite              |8        |\n",
            "|AMC Rebel SST                   |8        |\n",
            "|Ford Torino                     |8        |\n",
            "|Ford Galaxie 500                |8        |\n",
            "|Chevrolet Impala                |8        |\n",
            "|Plymouth Fury iii               |8        |\n",
            "|Pontiac Catalina                |8        |\n",
            "|AMC Ambassador DPL              |8        |\n",
            "|Citroen DS-21 Pallas            |4        |\n",
            "|Chevrolet Chevelle Concours (sw)|8        |\n",
            "|Ford Torino (sw)                |8        |\n",
            "|Plymouth Satellite (sw)         |8        |\n",
            "|AMC Rebel SST (sw)              |8        |\n",
            "|Dodge Challenger SE             |8        |\n",
            "|Plymouth 'Cuda 340              |8        |\n",
            "|Ford Mustang Boss 302           |8        |\n",
            "|Chevrolet Monte Carlo           |8        |\n",
            "|Buick Estate Wagon (sw)         |8        |\n",
            "+--------------------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85Lv3zSXCcOY"
      },
      "source": [
        "<a id='adding-new-columns'></a>\n",
        "### Adding New Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_Y7dcAHu-Uz"
      },
      "source": [
        "We will take a look at three cases here:\n",
        "\n",
        "1.   Adding a new column\n",
        "2.   Adding multiple columns\n",
        "3.   Deriving a new column from an exisitng one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFHUmRKZeCEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed01c11-52d6-4ab3-a1ff-0423ef192293"
      },
      "source": [
        "# CASE 1: Adding a new column\n",
        "# We will add a new column called 'first_column' at the end\n",
        "from pyspark.sql.functions import lit\n",
        "df = df.withColumn('first_column',lit(1))\n",
        "# lit means literal. It populates the row with the literal value given.\n",
        "# When adding static data / constant values, it is a good practice to use it.\n",
        "df.show(5,truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+\n",
            "|Car                      |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|first_column|\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+\n",
            "|Chevrolet Chevelle Malibu|18.0|8        |307.0       |130.0     |3504.0|12.0        |70   |US    |1           |\n",
            "|Buick Skylark 320        |15.0|8        |350.0       |165.0     |3693.0|11.5        |70   |US    |1           |\n",
            "|Plymouth Satellite       |18.0|8        |318.0       |150.0     |3436.0|11.0        |70   |US    |1           |\n",
            "|AMC Rebel SST            |16.0|8        |304.0       |150.0     |3433.0|12.0        |70   |US    |1           |\n",
            "|Ford Torino              |17.0|8        |302.0       |140.0     |3449.0|10.5        |70   |US    |1           |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9772_mHwAqL",
        "outputId": "fe35b15f-cedb-4bda-eaf8-f817c55162e0"
      },
      "source": [
        "# CASE 2: Adding multiple columns\n",
        "# We will add two new columns called 'second_column' and 'third_column' at the end\n",
        "df = df.withColumn('second_column', lit(2)) \\\n",
        "       .withColumn('third_column', lit('Third Column'))\n",
        "# lit means literal. It populates the row with the literal value given.\n",
        "# When adding static data / constant values, it is a good practice to use it.\n",
        "df.show(5,truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+-------------+------------+\n",
            "|Car                      |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|first_column|second_column|third_column|\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+-------------+------------+\n",
            "|Chevrolet Chevelle Malibu|18.0|8        |307.0       |130.0     |3504.0|12.0        |70   |US    |1           |2            |Third Column|\n",
            "|Buick Skylark 320        |15.0|8        |350.0       |165.0     |3693.0|11.5        |70   |US    |1           |2            |Third Column|\n",
            "|Plymouth Satellite       |18.0|8        |318.0       |150.0     |3436.0|11.0        |70   |US    |1           |2            |Third Column|\n",
            "|AMC Rebel SST            |16.0|8        |304.0       |150.0     |3433.0|12.0        |70   |US    |1           |2            |Third Column|\n",
            "|Ford Torino              |17.0|8        |302.0       |140.0     |3449.0|10.5        |70   |US    |1           |2            |Third Column|\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+-------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGaQS_pOwx_b",
        "outputId": "f21c6b33-4e2a-41bd-cbbc-6b8712de1cbd"
      },
      "source": [
        "# CASE 3: Deriving a new column from an exisitng one\n",
        "# We will add a new column called 'car_model' which has the value of car and model appended together with a space in between\n",
        "from pyspark.sql.functions import concat\n",
        "df = df.withColumn('car_model', concat(col(\"Car\"), lit(\" \"), col(\"model\")))\n",
        "# lit means literal. It populates the row with the literal value given.\n",
        "# When adding static data / constant values, it is a good practice to use it.\n",
        "df.show(5,truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+-------------+------------+----------------------------+\n",
            "|Car                      |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|first_column|second_column|third_column|car_model                   |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+-------------+------------+----------------------------+\n",
            "|Chevrolet Chevelle Malibu|18.0|8        |307.0       |130.0     |3504.0|12.0        |70   |US    |1           |2            |Third Column|Chevrolet Chevelle Malibu 70|\n",
            "|Buick Skylark 320        |15.0|8        |350.0       |165.0     |3693.0|11.5        |70   |US    |1           |2            |Third Column|Buick Skylark 320 70        |\n",
            "|Plymouth Satellite       |18.0|8        |318.0       |150.0     |3436.0|11.0        |70   |US    |1           |2            |Third Column|Plymouth Satellite 70       |\n",
            "|AMC Rebel SST            |16.0|8        |304.0       |150.0     |3433.0|12.0        |70   |US    |1           |2            |Third Column|AMC Rebel SST 70            |\n",
            "|Ford Torino              |17.0|8        |302.0       |140.0     |3449.0|10.5        |70   |US    |1           |2            |Third Column|Ford Torino 70              |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+-------------+------------+----------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeHExg-zxf5r"
      },
      "source": [
        "As we can see, the new column car model has been created from existing columns. Since our aim was to create a column which has the value of car and model appended together with a space in between we have used the `concat` operator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlMf04i2CjDC"
      },
      "source": [
        "<a id='renaming-columns'></a>\n",
        "### Renaming Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwGKbSHvxxxG"
      },
      "source": [
        "We use the `withColumnRenamed` function to rename a columm in PySpark. Let us see it in action below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJqgy6lKfk2o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abdd234-5373-4cbd-89e0-04312ac6123d"
      },
      "source": [
        "#Renaming a column in PySpark\n",
        "df = df.withColumnRenamed('first_column', 'new_column_one') \\\n",
        "       .withColumnRenamed('second_column', 'new_column_two') \\\n",
        "       .withColumnRenamed('third_column', 'new_column_three')\n",
        "df.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------+----+---------+------------+----------+------+------------+-----+------+--------------+--------------+----------------+-----------------------------------+\n",
            "|Car                             |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|new_column_one|new_column_two|new_column_three|car_model                          |\n",
            "+--------------------------------+----+---------+------------+----------+------+------------+-----+------+--------------+--------------+----------------+-----------------------------------+\n",
            "|Chevrolet Chevelle Malibu       |18.0|8        |307.0       |130.0     |3504.0|12.0        |70   |US    |1             |2             |Third Column    |Chevrolet Chevelle Malibu 70       |\n",
            "|Buick Skylark 320               |15.0|8        |350.0       |165.0     |3693.0|11.5        |70   |US    |1             |2             |Third Column    |Buick Skylark 320 70               |\n",
            "|Plymouth Satellite              |18.0|8        |318.0       |150.0     |3436.0|11.0        |70   |US    |1             |2             |Third Column    |Plymouth Satellite 70              |\n",
            "|AMC Rebel SST                   |16.0|8        |304.0       |150.0     |3433.0|12.0        |70   |US    |1             |2             |Third Column    |AMC Rebel SST 70                   |\n",
            "|Ford Torino                     |17.0|8        |302.0       |140.0     |3449.0|10.5        |70   |US    |1             |2             |Third Column    |Ford Torino 70                     |\n",
            "|Ford Galaxie 500                |15.0|8        |429.0       |198.0     |4341.0|10.0        |70   |US    |1             |2             |Third Column    |Ford Galaxie 500 70                |\n",
            "|Chevrolet Impala                |14.0|8        |454.0       |220.0     |4354.0|9.0         |70   |US    |1             |2             |Third Column    |Chevrolet Impala 70                |\n",
            "|Plymouth Fury iii               |14.0|8        |440.0       |215.0     |4312.0|8.5         |70   |US    |1             |2             |Third Column    |Plymouth Fury iii 70               |\n",
            "|Pontiac Catalina                |14.0|8        |455.0       |225.0     |4425.0|10.0        |70   |US    |1             |2             |Third Column    |Pontiac Catalina 70                |\n",
            "|AMC Ambassador DPL              |15.0|8        |390.0       |190.0     |3850.0|8.5         |70   |US    |1             |2             |Third Column    |AMC Ambassador DPL 70              |\n",
            "|Citroen DS-21 Pallas            |0.0 |4        |133.0       |115.0     |3090.0|17.5        |70   |Europe|1             |2             |Third Column    |Citroen DS-21 Pallas 70            |\n",
            "|Chevrolet Chevelle Concours (sw)|0.0 |8        |350.0       |165.0     |4142.0|11.5        |70   |US    |1             |2             |Third Column    |Chevrolet Chevelle Concours (sw) 70|\n",
            "|Ford Torino (sw)                |0.0 |8        |351.0       |153.0     |4034.0|11.0        |70   |US    |1             |2             |Third Column    |Ford Torino (sw) 70                |\n",
            "|Plymouth Satellite (sw)         |0.0 |8        |383.0       |175.0     |4166.0|10.5        |70   |US    |1             |2             |Third Column    |Plymouth Satellite (sw) 70         |\n",
            "|AMC Rebel SST (sw)              |0.0 |8        |360.0       |175.0     |3850.0|11.0        |70   |US    |1             |2             |Third Column    |AMC Rebel SST (sw) 70              |\n",
            "|Dodge Challenger SE             |15.0|8        |383.0       |170.0     |3563.0|10.0        |70   |US    |1             |2             |Third Column    |Dodge Challenger SE 70             |\n",
            "|Plymouth 'Cuda 340              |14.0|8        |340.0       |160.0     |3609.0|8.0         |70   |US    |1             |2             |Third Column    |Plymouth 'Cuda 340 70              |\n",
            "|Ford Mustang Boss 302           |0.0 |8        |302.0       |140.0     |3353.0|8.0         |70   |US    |1             |2             |Third Column    |Ford Mustang Boss 302 70           |\n",
            "|Chevrolet Monte Carlo           |15.0|8        |400.0       |150.0     |3761.0|9.5         |70   |US    |1             |2             |Third Column    |Chevrolet Monte Carlo 70           |\n",
            "|Buick Estate Wagon (sw)         |14.0|8        |455.0       |225.0     |3086.0|10.0        |70   |US    |1             |2             |Third Column    |Buick Estate Wagon (sw) 70         |\n",
            "+--------------------------------+----+---------+------------+----------+------+------------+-----+------+--------------+--------------+----------------+-----------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CDifVC2Cnml"
      },
      "source": [
        "<a id='grouping-by-columns'></a>\n",
        "### Grouping By Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wlB76FdyS0W"
      },
      "source": [
        "Here, we see the Dataframe API way of grouping values. We will discuss how to:\n",
        "\n",
        "\n",
        "1.   Group By a single column\n",
        "2.   Group By multiple columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1ek2opVfqea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eab0db5-13ab-4868-871b-da4fb16ab768"
      },
      "source": [
        "# Group By a column in PySpark\n",
        "df.groupBy('Origin').count().show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|Origin|count|\n",
            "+------+-----+\n",
            "|Europe|   73|\n",
            "|    US|  254|\n",
            "| Japan|   79|\n",
            "+------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUh_TWcOysoL",
        "outputId": "dad5b95e-4949-4259-cbd4-b0103d6daec9"
      },
      "source": [
        "# Group By multiple columns in PySpark\n",
        "df.groupBy('Origin', 'Model').count().show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+-----+\n",
            "|Origin|Model|count|\n",
            "+------+-----+-----+\n",
            "|Europe|   71|    5|\n",
            "|Europe|   80|    9|\n",
            "|Europe|   79|    4|\n",
            "| Japan|   75|    4|\n",
            "|    US|   72|   18|\n",
            "+------+-----+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbpEj9fECrW3"
      },
      "source": [
        "<a id='removing-columns'></a>\n",
        "### Removing Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsb9PXxpfnmh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "601341ee-c131-46e3-9331-2e93664f9bb2"
      },
      "source": [
        "#Remove columns in PySpark\n",
        "df = df.drop('new_column_one')\n",
        "df.show(5,truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+--------------+----------------+----------------------------+\n",
            "|Car                      |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|new_column_two|new_column_three|car_model                   |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+--------------+----------------+----------------------------+\n",
            "|Chevrolet Chevelle Malibu|18.0|8        |307.0       |130.0     |3504.0|12.0        |70   |US    |2             |Third Column    |Chevrolet Chevelle Malibu 70|\n",
            "|Buick Skylark 320        |15.0|8        |350.0       |165.0     |3693.0|11.5        |70   |US    |2             |Third Column    |Buick Skylark 320 70        |\n",
            "|Plymouth Satellite       |18.0|8        |318.0       |150.0     |3436.0|11.0        |70   |US    |2             |Third Column    |Plymouth Satellite 70       |\n",
            "|AMC Rebel SST            |16.0|8        |304.0       |150.0     |3433.0|12.0        |70   |US    |2             |Third Column    |AMC Rebel SST 70            |\n",
            "|Ford Torino              |17.0|8        |302.0       |140.0     |3449.0|10.5        |70   |US    |2             |Third Column    |Ford Torino 70              |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+--------------+----------------+----------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKOXrXtvzK_0",
        "outputId": "329e9696-7a60-4fcf-dc56-4d6cbcd5dc7a"
      },
      "source": [
        "#Remove multiple columnss in one go\n",
        "df = df.drop('new_column_two') \\\n",
        "       .drop('new_column_three')\n",
        "df.show(5,truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+----------------------------+\n",
            "|Car                      |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|car_model                   |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+----------------------------+\n",
            "|Chevrolet Chevelle Malibu|18.0|8        |307.0       |130.0     |3504.0|12.0        |70   |US    |Chevrolet Chevelle Malibu 70|\n",
            "|Buick Skylark 320        |15.0|8        |350.0       |165.0     |3693.0|11.5        |70   |US    |Buick Skylark 320 70        |\n",
            "|Plymouth Satellite       |18.0|8        |318.0       |150.0     |3436.0|11.0        |70   |US    |Plymouth Satellite 70       |\n",
            "|AMC Rebel SST            |16.0|8        |304.0       |150.0     |3433.0|12.0        |70   |US    |AMC Rebel SST 70            |\n",
            "|Ford Torino              |17.0|8        |302.0       |140.0     |3449.0|10.5        |70   |US    |Ford Torino 70              |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+----------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbKK5iHwmIoV"
      },
      "source": [
        "<a id='dataframe-operations-on-rows'></a>\n",
        "## DataFrame Operations on Rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Quwx3KlLzeq9"
      },
      "source": [
        "We will discuss the follwoing in this section:\n",
        "\n",
        "1.   Filtering Rows\n",
        "2. \t Get Distinct Rows\n",
        "3.   Sorting Rows\n",
        "4.   Union Dataframes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bKlvX-SH-Wy"
      },
      "source": [
        "<a id='filtering-rows'></a>\n",
        "### Filtering Rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNfcjOIknA3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7319fc9b-76cb-428f-dbb6-99f25b80b79c"
      },
      "source": [
        "# Filtering rows in PySpark\n",
        "total_count = df.count()\n",
        "print(\"TOTAL RECORD COUNT: \" + str(total_count))\n",
        "europe_filtered_count = df.filter(col('Origin')=='Europe').count()\n",
        "print(\"EUROPE FILTERED RECORD COUNT: \" + str(europe_filtered_count))\n",
        "df.filter(col('Origin')=='Europe').show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOTAL RECORD COUNT: 406\n",
            "EUROPE FILTERED RECORD COUNT: 73\n",
            "+----------------------------+----+---------+------------+----------+------+------------+-----+------+-------------------------------+\n",
            "|Car                         |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|car_model                      |\n",
            "+----------------------------+----+---------+------------+----------+------+------------+-----+------+-------------------------------+\n",
            "|Citroen DS-21 Pallas        |0.0 |4        |133.0       |115.0     |3090.0|17.5        |70   |Europe|Citroen DS-21 Pallas 70        |\n",
            "|Volkswagen 1131 Deluxe Sedan|26.0|4        |97.0        |46.0      |1835.0|20.5        |70   |Europe|Volkswagen 1131 Deluxe Sedan 70|\n",
            "|Peugeot 504                 |25.0|4        |110.0       |87.0      |2672.0|17.5        |70   |Europe|Peugeot 504 70                 |\n",
            "|Audi 100 LS                 |24.0|4        |107.0       |90.0      |2430.0|14.5        |70   |Europe|Audi 100 LS 70                 |\n",
            "|Saab 99e                    |25.0|4        |104.0       |95.0      |2375.0|17.5        |70   |Europe|Saab 99e 70                    |\n",
            "|BMW 2002                    |26.0|4        |121.0       |113.0     |2234.0|12.5        |70   |Europe|BMW 2002 70                    |\n",
            "|Volkswagen Super Beetle 117 |0.0 |4        |97.0        |48.0      |1978.0|20.0        |71   |Europe|Volkswagen Super Beetle 117 71 |\n",
            "|Opel 1900                   |28.0|4        |116.0       |90.0      |2123.0|14.0        |71   |Europe|Opel 1900 71                   |\n",
            "|Peugeot 304                 |30.0|4        |79.0        |70.0      |2074.0|19.5        |71   |Europe|Peugeot 304 71                 |\n",
            "|Fiat 124B                   |30.0|4        |88.0        |76.0      |2065.0|14.5        |71   |Europe|Fiat 124B 71                   |\n",
            "|Volkswagen Model 111        |27.0|4        |97.0        |60.0      |1834.0|19.0        |71   |Europe|Volkswagen Model 111 71        |\n",
            "|Volkswagen Type 3           |23.0|4        |97.0        |54.0      |2254.0|23.5        |72   |Europe|Volkswagen Type 3 72           |\n",
            "|Volvo 145e (sw)             |18.0|4        |121.0       |112.0     |2933.0|14.5        |72   |Europe|Volvo 145e (sw) 72             |\n",
            "|Volkswagen 411 (sw)         |22.0|4        |121.0       |76.0      |2511.0|18.0        |72   |Europe|Volkswagen 411 (sw) 72         |\n",
            "|Peugeot 504 (sw)            |21.0|4        |120.0       |87.0      |2979.0|19.5        |72   |Europe|Peugeot 504 (sw) 72            |\n",
            "|Renault 12 (sw)             |26.0|4        |96.0        |69.0      |2189.0|18.0        |72   |Europe|Renault 12 (sw) 72             |\n",
            "|Volkswagen Super Beetle     |26.0|4        |97.0        |46.0      |1950.0|21.0        |73   |Europe|Volkswagen Super Beetle 73     |\n",
            "|Fiat 124 Sport Coupe        |26.0|4        |98.0        |90.0      |2265.0|15.5        |73   |Europe|Fiat 124 Sport Coupe 73        |\n",
            "|Fiat 128                    |29.0|4        |68.0        |49.0      |1867.0|19.5        |73   |Europe|Fiat 128 73                    |\n",
            "|Opel Manta                  |24.0|4        |116.0       |75.0      |2158.0|15.5        |73   |Europe|Opel Manta 73                  |\n",
            "+----------------------------+----+---------+------------+----------+------+------------+-----+------+-------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXJxRwBQ1lyd",
        "outputId": "06fcc49c-c21e-47c5-ee14-324ae724e274"
      },
      "source": [
        "# Filtering rows in PySpark based on Multiple conditions\n",
        "total_count = df.count()\n",
        "print(\"TOTAL RECORD COUNT: \" + str(total_count))\n",
        "europe_filtered_count = df.filter((col('Origin')=='Europe') &\n",
        "                                  (col('Cylinders')==4)).count() # Two conditions added here\n",
        "print(\"EUROPE FILTERED RECORD COUNT: \" + str(europe_filtered_count))\n",
        "df.filter(col('Origin')=='Europe').show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOTAL RECORD COUNT: 406\n",
            "EUROPE FILTERED RECORD COUNT: 66\n",
            "+----------------------------+----+---------+------------+----------+------+------------+-----+------+-------------------------------+\n",
            "|Car                         |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|car_model                      |\n",
            "+----------------------------+----+---------+------------+----------+------+------------+-----+------+-------------------------------+\n",
            "|Citroen DS-21 Pallas        |0.0 |4        |133.0       |115.0     |3090.0|17.5        |70   |Europe|Citroen DS-21 Pallas 70        |\n",
            "|Volkswagen 1131 Deluxe Sedan|26.0|4        |97.0        |46.0      |1835.0|20.5        |70   |Europe|Volkswagen 1131 Deluxe Sedan 70|\n",
            "|Peugeot 504                 |25.0|4        |110.0       |87.0      |2672.0|17.5        |70   |Europe|Peugeot 504 70                 |\n",
            "|Audi 100 LS                 |24.0|4        |107.0       |90.0      |2430.0|14.5        |70   |Europe|Audi 100 LS 70                 |\n",
            "|Saab 99e                    |25.0|4        |104.0       |95.0      |2375.0|17.5        |70   |Europe|Saab 99e 70                    |\n",
            "|BMW 2002                    |26.0|4        |121.0       |113.0     |2234.0|12.5        |70   |Europe|BMW 2002 70                    |\n",
            "|Volkswagen Super Beetle 117 |0.0 |4        |97.0        |48.0      |1978.0|20.0        |71   |Europe|Volkswagen Super Beetle 117 71 |\n",
            "|Opel 1900                   |28.0|4        |116.0       |90.0      |2123.0|14.0        |71   |Europe|Opel 1900 71                   |\n",
            "|Peugeot 304                 |30.0|4        |79.0        |70.0      |2074.0|19.5        |71   |Europe|Peugeot 304 71                 |\n",
            "|Fiat 124B                   |30.0|4        |88.0        |76.0      |2065.0|14.5        |71   |Europe|Fiat 124B 71                   |\n",
            "|Volkswagen Model 111        |27.0|4        |97.0        |60.0      |1834.0|19.0        |71   |Europe|Volkswagen Model 111 71        |\n",
            "|Volkswagen Type 3           |23.0|4        |97.0        |54.0      |2254.0|23.5        |72   |Europe|Volkswagen Type 3 72           |\n",
            "|Volvo 145e (sw)             |18.0|4        |121.0       |112.0     |2933.0|14.5        |72   |Europe|Volvo 145e (sw) 72             |\n",
            "|Volkswagen 411 (sw)         |22.0|4        |121.0       |76.0      |2511.0|18.0        |72   |Europe|Volkswagen 411 (sw) 72         |\n",
            "|Peugeot 504 (sw)            |21.0|4        |120.0       |87.0      |2979.0|19.5        |72   |Europe|Peugeot 504 (sw) 72            |\n",
            "|Renault 12 (sw)             |26.0|4        |96.0        |69.0      |2189.0|18.0        |72   |Europe|Renault 12 (sw) 72             |\n",
            "|Volkswagen Super Beetle     |26.0|4        |97.0        |46.0      |1950.0|21.0        |73   |Europe|Volkswagen Super Beetle 73     |\n",
            "|Fiat 124 Sport Coupe        |26.0|4        |98.0        |90.0      |2265.0|15.5        |73   |Europe|Fiat 124 Sport Coupe 73        |\n",
            "|Fiat 128                    |29.0|4        |68.0        |49.0      |1867.0|19.5        |73   |Europe|Fiat 128 73                    |\n",
            "|Opel Manta                  |24.0|4        |116.0       |75.0      |2158.0|15.5        |73   |Europe|Opel Manta 73                  |\n",
            "+----------------------------+----+---------+------------+----------+------+------------+-----+------+-------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLU-a4auIEvh"
      },
      "source": [
        "<a id='get-distinct-rows'></a>\n",
        "### Get Distinct Rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1RKg1UrmBQz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2713c65-a75b-4b64-b6e1-181b96259649"
      },
      "source": [
        "#Get Unique Rows in PySpark\n",
        "df.select('Origin').distinct().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+\n",
            "|Origin|\n",
            "+------+\n",
            "|Europe|\n",
            "|    US|\n",
            "| Japan|\n",
            "+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LQWXPXt0g0N",
        "outputId": "6098ccd8-ae6d-4772-b18a-aad49f8d58c0"
      },
      "source": [
        "#Get Unique Rows in PySpark based on mutliple columns\n",
        "df.select('Origin','model').distinct().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|Origin|model|\n",
            "+------+-----+\n",
            "|Europe|   71|\n",
            "|Europe|   80|\n",
            "|Europe|   79|\n",
            "| Japan|   75|\n",
            "|    US|   72|\n",
            "|    US|   80|\n",
            "|Europe|   74|\n",
            "| Japan|   79|\n",
            "|Europe|   76|\n",
            "|    US|   75|\n",
            "| Japan|   77|\n",
            "|    US|   82|\n",
            "| Japan|   80|\n",
            "| Japan|   78|\n",
            "|    US|   78|\n",
            "|Europe|   75|\n",
            "|    US|   71|\n",
            "|    US|   77|\n",
            "| Japan|   70|\n",
            "| Japan|   71|\n",
            "+------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-069UYUwIIYI"
      },
      "source": [
        "<a id='sorting-rows'></a>\n",
        "### Sorting Rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZpeJvz0nkBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa965b71-521e-48b7-b440-0033a4ae6599"
      },
      "source": [
        "# Sort Rows in PySpark\n",
        "# By default the data will be sorted in ascending order\n",
        "df.orderBy('Cylinders').show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------+----+---------+------------+----------+------+------------+-----+------+-------------------------------+\n",
            "|Car                         |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|car_model                      |\n",
            "+----------------------------+----+---------+------------+----------+------+------------+-----+------+-------------------------------+\n",
            "|Mazda RX-4                  |21.5|3        |80.0        |110.0     |2720.0|13.5        |77   |Japan |Mazda RX-4 77                  |\n",
            "|Mazda RX-7 GS               |23.7|3        |70.0        |100.0     |2420.0|12.5        |80   |Japan |Mazda RX-7 GS 80               |\n",
            "|Mazda RX2 Coupe             |19.0|3        |70.0        |97.0      |2330.0|13.5        |72   |Japan |Mazda RX2 Coupe 72             |\n",
            "|Mazda RX3                   |18.0|3        |70.0        |90.0      |2124.0|13.5        |73   |Japan |Mazda RX3 73                   |\n",
            "|Datsun 510 (sw)             |28.0|4        |97.0        |92.0      |2288.0|17.0        |72   |Japan |Datsun 510 (sw) 72             |\n",
            "|Opel 1900                   |28.0|4        |116.0       |90.0      |2123.0|14.0        |71   |Europe|Opel 1900 71                   |\n",
            "|Mercury Capri 2000          |23.0|4        |122.0       |86.0      |2220.0|14.0        |71   |US    |Mercury Capri 2000 71          |\n",
            "|Volkswagen 1131 Deluxe Sedan|26.0|4        |97.0        |46.0      |1835.0|20.5        |70   |Europe|Volkswagen 1131 Deluxe Sedan 70|\n",
            "|Peugeot 304                 |30.0|4        |79.0        |70.0      |2074.0|19.5        |71   |Europe|Peugeot 304 71                 |\n",
            "|Fiat 124B                   |30.0|4        |88.0        |76.0      |2065.0|14.5        |71   |Europe|Fiat 124B 71                   |\n",
            "|Chevrolet Vega (sw)         |22.0|4        |140.0       |72.0      |2408.0|19.0        |71   |US    |Chevrolet Vega (sw) 71         |\n",
            "|Datsun 1200                 |35.0|4        |72.0        |69.0      |1613.0|18.0        |71   |Japan |Datsun 1200 71                 |\n",
            "|Volkswagen Model 111        |27.0|4        |97.0        |60.0      |1834.0|19.0        |71   |Europe|Volkswagen Model 111 71        |\n",
            "|Volkswagen Type 3           |23.0|4        |97.0        |54.0      |2254.0|23.5        |72   |Europe|Volkswagen Type 3 72           |\n",
            "|Audi 100 LS                 |24.0|4        |107.0       |90.0      |2430.0|14.5        |70   |Europe|Audi 100 LS 70                 |\n",
            "|BMW 2002                    |26.0|4        |121.0       |113.0     |2234.0|12.5        |70   |Europe|BMW 2002 70                    |\n",
            "|Toyota Corolla 1200         |31.0|4        |71.0        |65.0      |1773.0|19.0        |71   |Japan |Toyota Corolla 1200 71         |\n",
            "|Chevrolet Vega 2300         |28.0|4        |140.0       |90.0      |2264.0|15.5        |71   |US    |Chevrolet Vega 2300 71         |\n",
            "|Ford Pinto                  |25.0|4        |98.0        |0.0       |2046.0|19.0        |71   |US    |Ford Pinto 71                  |\n",
            "|Dodge Colt Hardtop          |25.0|4        |97.5        |80.0      |2126.0|17.0        |72   |US    |Dodge Colt Hardtop 72          |\n",
            "+----------------------------+----+---------+------------+----------+------+------------+-----+------+-------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1CEwofMJV-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46809931-e309-4482-adf1-2bd7cfdac811"
      },
      "source": [
        "# To change the sorting order, you can use the ascending parameter\n",
        "df.orderBy('Cylinders', ascending=False).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+----------------------------+\n",
            "|Car                      |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|car_model                   |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+----------------------------+\n",
            "|Plymouth 'Cuda 340       |14.0|8        |340.0       |160.0     |3609.0|8.0         |70   |US    |Plymouth 'Cuda 340 70       |\n",
            "|Pontiac Safari (sw)      |13.0|8        |400.0       |175.0     |5140.0|12.0        |71   |US    |Pontiac Safari (sw) 71      |\n",
            "|Ford Mustang Boss 302    |0.0 |8        |302.0       |140.0     |3353.0|8.0         |70   |US    |Ford Mustang Boss 302 70    |\n",
            "|Buick Skylark 320        |15.0|8        |350.0       |165.0     |3693.0|11.5        |70   |US    |Buick Skylark 320 70        |\n",
            "|Chevrolet Monte Carlo    |15.0|8        |400.0       |150.0     |3761.0|9.5         |70   |US    |Chevrolet Monte Carlo 70    |\n",
            "|AMC Rebel SST            |16.0|8        |304.0       |150.0     |3433.0|12.0        |70   |US    |AMC Rebel SST 70            |\n",
            "|Buick Estate Wagon (sw)  |14.0|8        |455.0       |225.0     |3086.0|10.0        |70   |US    |Buick Estate Wagon (sw) 70  |\n",
            "|Ford Galaxie 500         |15.0|8        |429.0       |198.0     |4341.0|10.0        |70   |US    |Ford Galaxie 500 70         |\n",
            "|Ford F250                |10.0|8        |360.0       |215.0     |4615.0|14.0        |70   |US    |Ford F250 70                |\n",
            "|Plymouth Fury iii        |14.0|8        |440.0       |215.0     |4312.0|8.5         |70   |US    |Plymouth Fury iii 70        |\n",
            "|Chevy C20                |10.0|8        |307.0       |200.0     |4376.0|15.0        |70   |US    |Chevy C20 70                |\n",
            "|AMC Ambassador DPL       |15.0|8        |390.0       |190.0     |3850.0|8.5         |70   |US    |AMC Ambassador DPL 70       |\n",
            "|Dodge D200               |11.0|8        |318.0       |210.0     |4382.0|13.5        |70   |US    |Dodge D200 70               |\n",
            "|Ford Torino (sw)         |0.0 |8        |351.0       |153.0     |4034.0|11.0        |70   |US    |Ford Torino (sw) 70         |\n",
            "|Hi 1200D                 |9.0 |8        |304.0       |193.0     |4732.0|18.5        |70   |US    |Hi 1200D 70                 |\n",
            "|AMC Rebel SST (sw)       |0.0 |8        |360.0       |175.0     |3850.0|11.0        |70   |US    |AMC Rebel SST (sw) 70       |\n",
            "|Chevrolet Impala         |14.0|8        |350.0       |165.0     |4209.0|12.0        |71   |US    |Chevrolet Impala 71         |\n",
            "|Chevrolet Chevelle Malibu|18.0|8        |307.0       |130.0     |3504.0|12.0        |70   |US    |Chevrolet Chevelle Malibu 70|\n",
            "|Pontiac Catalina Brougham|14.0|8        |400.0       |175.0     |4464.0|11.5        |71   |US    |Pontiac Catalina Brougham 71|\n",
            "|Ford Torino              |17.0|8        |302.0       |140.0     |3449.0|10.5        |70   |US    |Ford Torino 70              |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+----------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx3W4aeL5A4O",
        "outputId": "6671ffa3-9024-4a5f-9342-2cba4483e387"
      },
      "source": [
        "# Using groupBy aand orderBy together\n",
        "df.groupBy(\"Origin\").count().orderBy('count', ascending=False).show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|Origin|count|\n",
            "+------+-----+\n",
            "|    US|  254|\n",
            "| Japan|   79|\n",
            "|Europe|   73|\n",
            "+------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN0-A_JsIX-X"
      },
      "source": [
        "<a id='union-dataframes'></a>\n",
        "### Union Dataframes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH0KOaBrJt6v"
      },
      "source": [
        "You will see three main methods for performing union of dataframes. It is important to know the difference between them and which one is preferred:\n",
        "\n",
        "*   `union()` – It is used to merge two DataFrames of the same structure/schema. If schemas are not the same, it returns an error\n",
        "*   `unionAll()` – This function is deprecated since Spark 2.0.0, and replaced with union()\n",
        "*   `unionByName()` - This function is used to merge two dataframes based on column name.\n",
        "\n",
        "> Since `unionAll()` is deprecated, **`union()` is the preferred method for merging dataframes.**\n",
        "<br>\n",
        "> The difference between `unionByName()` and `union()` is that `unionByName()` resolves columns by name, not by position.\n",
        "\n",
        "In other SQLs, Union eliminates the duplicates but UnionAll merges two datasets, thereby including duplicate records. But, in PySpark, both behave the same and includes duplicate records. The recommendation is to use `distinct()` or `dropDuplicates()` to remove duplicate records."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCZIzfYmnx--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd0de201-5f82-4ce3-e15c-35b7665ad079"
      },
      "source": [
        "# CASE 1: Union When columns are in order\n",
        "df = spark.read.csv('cars.csv', header=True, sep=\";\", inferSchema=True)\n",
        "europe_cars = df.filter((col('Origin')=='Europe') & (col('Cylinders')==5))\n",
        "japan_cars = df.filter((col('Origin')=='Japan') & (col('Cylinders')==3))\n",
        "print(\"EUROPE CARS: \"+str(europe_cars.count()))\n",
        "print(\"JAPAN CARS: \"+str(japan_cars.count()))\n",
        "print(\"AFTER UNION: \"+str(europe_cars.union(japan_cars).count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EUROPE CARS: 3\n",
            "JAPAN CARS: 4\n",
            "AFTER UNION: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pfPzVOFqC_8"
      },
      "source": [
        "**Result:**\n",
        "\n",
        "> As you can see here, there were 3 cars from Europe with 5 Cylinders, and 4 cars from Japan with 3 Cylinders. After union, there are 7 cars in total.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjWjzWBoMxx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11237d45-cacc-403c-e971-6e2717a32135"
      },
      "source": [
        "# CASE 1: Union When columns are not in order\n",
        "# Creating two dataframes with jumbled columns\n",
        "df1 = spark.createDataFrame([[1, 2, 3]], [\"col0\", \"col1\", \"col2\"])\n",
        "df2 = spark.createDataFrame([[4, 5, 6]], [\"col1\", \"col2\", \"col0\"])\n",
        "df1.unionByName(df2).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+----+----+\n",
            "|col0|col1|col2|\n",
            "+----+----+----+\n",
            "|   1|   2|   3|\n",
            "|   6|   4|   5|\n",
            "+----+----+----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX33t8e3PyGy"
      },
      "source": [
        "**Result:**\n",
        "\n",
        "> As you can see here, the two dataframes have been successfully merged based on their column names.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHjILb1DriuX"
      },
      "source": [
        "<a id='common-data-manipulation-functions'></a>\n",
        "## Common Data Manipulation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3vlC7ZerlKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89d386c3-e9c2-4532-c086-f8b00cc38881"
      },
      "source": [
        "# Functions available in PySpark\n",
        "from pyspark.sql import functions\n",
        "# Similar to python, we can use the dir function to view the avaiable functions\n",
        "print(dir(functions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Column', 'DataFrame', 'DataType', 'PandasUDFType', 'PythonEvalType', 'SparkContext', 'StringType', 'UserDefinedFunction', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_create_column_from_literal', '_create_lambda', '_create_udf', '_get_get_jvm_function', '_get_lambda_parameters', '_invoke_binary_math_function', '_invoke_function', '_invoke_function_over_column', '_invoke_higher_order_function', '_options_to_str', '_test', '_to_java_column', '_to_seq', '_unresolved_named_lambda_variable', 'abs', 'acos', 'acosh', 'add_months', 'aggregate', 'approxCountDistinct', 'approx_count_distinct', 'array', 'array_contains', 'array_distinct', 'array_except', 'array_intersect', 'array_join', 'array_max', 'array_min', 'array_position', 'array_remove', 'array_repeat', 'array_sort', 'array_union', 'arrays_overlap', 'arrays_zip', 'asc', 'asc_nulls_first', 'asc_nulls_last', 'ascii', 'asin', 'asinh', 'assert_true', 'atan', 'atan2', 'atanh', 'avg', 'base64', 'bin', 'bitwiseNOT', 'broadcast', 'bround', 'bucket', 'cbrt', 'ceil', 'coalesce', 'col', 'collect_list', 'collect_set', 'column', 'concat', 'concat_ws', 'conv', 'corr', 'cos', 'cosh', 'count', 'countDistinct', 'covar_pop', 'covar_samp', 'crc32', 'create_map', 'cume_dist', 'current_date', 'current_timestamp', 'date_add', 'date_format', 'date_sub', 'date_trunc', 'datediff', 'dayofmonth', 'dayofweek', 'dayofyear', 'days', 'decode', 'degrees', 'dense_rank', 'desc', 'desc_nulls_first', 'desc_nulls_last', 'element_at', 'encode', 'exists', 'exp', 'explode', 'explode_outer', 'expm1', 'expr', 'factorial', 'filter', 'first', 'flatten', 'floor', 'forall', 'format_number', 'format_string', 'from_csv', 'from_json', 'from_unixtime', 'from_utc_timestamp', 'functools', 'get_json_object', 'greatest', 'grouping', 'grouping_id', 'hash', 'hex', 'hour', 'hours', 'hypot', 'initcap', 'input_file_name', 'instr', 'isnan', 'isnull', 'json_tuple', 'kurtosis', 'lag', 'last', 'last_day', 'lead', 'least', 'length', 'levenshtein', 'lit', 'locate', 'log', 'log10', 'log1p', 'log2', 'lower', 'lpad', 'ltrim', 'map_concat', 'map_entries', 'map_filter', 'map_from_arrays', 'map_from_entries', 'map_keys', 'map_values', 'map_zip_with', 'max', 'md5', 'mean', 'min', 'minute', 'monotonically_increasing_id', 'month', 'months', 'months_between', 'nanvl', 'next_day', 'nth_value', 'ntile', 'overlay', 'pandas_udf', 'percent_rank', 'percentile_approx', 'posexplode', 'posexplode_outer', 'pow', 'quarter', 'radians', 'raise_error', 'rand', 'randn', 'rank', 'regexp_extract', 'regexp_replace', 'repeat', 'reverse', 'rint', 'round', 'row_number', 'rpad', 'rtrim', 'schema_of_csv', 'schema_of_json', 'second', 'sequence', 'sha1', 'sha2', 'shiftLeft', 'shiftRight', 'shiftRightUnsigned', 'shuffle', 'signum', 'sin', 'since', 'sinh', 'size', 'skewness', 'slice', 'sort_array', 'soundex', 'spark_partition_id', 'split', 'sqrt', 'stddev', 'stddev_pop', 'stddev_samp', 'struct', 'substring', 'substring_index', 'sum', 'sumDistinct', 'sys', 'tan', 'tanh', 'timestamp_seconds', 'toDegrees', 'toRadians', 'to_csv', 'to_date', 'to_json', 'to_str', 'to_timestamp', 'to_utc_timestamp', 'transform', 'transform_keys', 'transform_values', 'translate', 'trim', 'trunc', 'udf', 'unbase64', 'unhex', 'unix_timestamp', 'upper', 'var_pop', 'var_samp', 'variance', 'warnings', 'weekofyear', 'when', 'window', 'xxhash64', 'year', 'years', 'zip_with']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIKigra7A34e"
      },
      "source": [
        "<a id='string-functions'></a>\n",
        "### String Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63QDccSjBqC4"
      },
      "source": [
        "# Loading the data\n",
        "from pyspark.sql.functions import col\n",
        "df = spark.read.csv('cars.csv', header=True, sep=\";\", inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiXWN8DUA9x6"
      },
      "source": [
        "**Display the Car column in exisitng, lower and upper characters, and the first 4 characters of the column**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52Gh9c99BZFr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c7cfa5-7363-4387-cb35-57ee79e22055"
      },
      "source": [
        "from pyspark.sql.functions import col,lower, upper, substring\n",
        "# Prints out the details of a function\n",
        "help(substring)\n",
        "# alias is used to rename the column name in the output\n",
        "df.select(col('Car'),lower(col('Car')),upper(col('Car')),substring(col('Car'),1,4).alias(\"concatenated value\")).show(5, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function substring in module pyspark.sql.functions:\n",
            "\n",
            "substring(str, pos, len)\n",
            "    Substring starts at `pos` and is of length `len` when str is String type or\n",
            "    returns the slice of byte array that starts at `pos` in byte and is of length `len`\n",
            "    when str is Binary type.\n",
            "    \n",
            "    .. versionadded:: 1.5.0\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    The position is not zero based, but 1 based index.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    >>> df = spark.createDataFrame([('abcd',)], ['s',])\n",
            "    >>> df.select(substring(df.s, 1, 2).alias('s')).collect()\n",
            "    [Row(s='ab')]\n",
            "\n",
            "+-------------------------+-------------------------+-------------------------+------------------+\n",
            "|Car                      |lower(Car)               |upper(Car)               |concatenated value|\n",
            "+-------------------------+-------------------------+-------------------------+------------------+\n",
            "|Chevrolet Chevelle Malibu|chevrolet chevelle malibu|CHEVROLET CHEVELLE MALIBU|Chev              |\n",
            "|Buick Skylark 320        |buick skylark 320        |BUICK SKYLARK 320        |Buic              |\n",
            "|Plymouth Satellite       |plymouth satellite       |PLYMOUTH SATELLITE       |Plym              |\n",
            "|AMC Rebel SST            |amc rebel sst            |AMC REBEL SST            |AMC               |\n",
            "|Ford Torino              |ford torino              |FORD TORINO              |Ford              |\n",
            "+-------------------------+-------------------------+-------------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZJFdTbk6rBt"
      },
      "source": [
        "**Concatenate the Car column and Model column and add a space between them.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lo951Cg6phi",
        "outputId": "e3921f2d-9a96-4a33-f397-c458ec391bf5"
      },
      "source": [
        "from pyspark.sql.functions import concat\n",
        "df.select(col(\"Car\"),col(\"model\"),concat(col(\"Car\"), lit(\" \"), col(\"model\"))).show(5, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------+-----+----------------------------+\n",
            "|Car                      |model|concat(Car,  , model)       |\n",
            "+-------------------------+-----+----------------------------+\n",
            "|Chevrolet Chevelle Malibu|70   |Chevrolet Chevelle Malibu 70|\n",
            "|Buick Skylark 320        |70   |Buick Skylark 320 70        |\n",
            "|Plymouth Satellite       |70   |Plymouth Satellite 70       |\n",
            "|AMC Rebel SST            |70   |AMC Rebel SST 70            |\n",
            "|Ford Torino              |70   |Ford Torino 70              |\n",
            "+-------------------------+-----+----------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldtA0wk9BMkT"
      },
      "source": [
        "<a id='numeric-functions'></a>\n",
        "### Numeric functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmz4G5LVBOs6"
      },
      "source": [
        "**Show the oldest date and the most recent date**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBDDH-YpBbdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d15146-4d47-45d4-af92-f536684fc7b3"
      },
      "source": [
        "from pyspark.sql.functions import min, max\n",
        "df.select(min(col('Weight')), max(col('Weight'))).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+-----------+\n",
            "|min(Weight)|max(Weight)|\n",
            "+-----------+-----------+\n",
            "|       1613|       5140|\n",
            "+-----------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTg-Royz7Nvi"
      },
      "source": [
        "**Add 10 to the minimum and maximum weight**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeiemMsI7Vm2",
        "outputId": "21d6646c-8e6e-47af-bef9-b92ee07c7df7"
      },
      "source": [
        "from pyspark.sql.functions import min, max, lit\n",
        "df.select(min(col('Weight'))+lit(10), max(col('Weight')+lit(10))).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------+------------------+\n",
            "|(min(Weight) + 10)|max((Weight + 10))|\n",
            "+------------------+------------------+\n",
            "|              1623|              5150|\n",
            "+------------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ6Ul9HGCwC3"
      },
      "source": [
        "<a id='operations-on-date'></a>\n",
        "### Operations on Date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1jmBN2qFHyk"
      },
      "source": [
        "> [PySpark follows SimpleDateFormat table of Java. Click here to view the docs.](https://docs.oracle.com/javase/7/docs/api/java/text/SimpleDateFormat.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCTeI_JvDCsH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3f4a392-00d7-422d-945c-8038b3804876"
      },
      "source": [
        "from pyspark.sql.functions import to_date, to_timestamp, lit\n",
        "df = spark.createDataFrame([('2019-12-25 13:30:00',)], ['DOB'])\n",
        "df.show()\n",
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+\n",
            "|                DOB|\n",
            "+-------------------+\n",
            "|2019-12-25 13:30:00|\n",
            "+-------------------+\n",
            "\n",
            "root\n",
            " |-- DOB: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH8ja1eHEW8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cef04c2-6c6f-494d-db9a-a4c17599b65c"
      },
      "source": [
        "df = spark.createDataFrame([('2019-12-25 13:30:00',)], ['DOB'])\n",
        "df = df.select(to_date(col('DOB'),'yyyy-MM-dd HH:mm:ss'), to_timestamp(col('DOB'),'yyyy-MM-dd HH:mm:ss'))\n",
        "df.show()\n",
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------+--------------------------------------+\n",
            "|to_date(DOB, yyyy-MM-dd HH:mm:ss)|to_timestamp(DOB, yyyy-MM-dd HH:mm:ss)|\n",
            "+---------------------------------+--------------------------------------+\n",
            "|                       2019-12-25|                   2019-12-25 13:30:00|\n",
            "+---------------------------------+--------------------------------------+\n",
            "\n",
            "root\n",
            " |-- to_date(DOB, yyyy-MM-dd HH:mm:ss): date (nullable = true)\n",
            " |-- to_timestamp(DOB, yyyy-MM-dd HH:mm:ss): timestamp (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g9m_8PPErI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854b3a71-bf83-4be8-c282-d94cc914c91f"
      },
      "source": [
        "df = spark.createDataFrame([('25/Dec/2019 13:30:00',)], ['DOB'])\n",
        "df = df.select(to_date(col('DOB'),'dd/MMM/yyyy HH:mm:ss'), to_timestamp(col('DOB'),'dd/MMM/yyyy HH:mm:ss'))\n",
        "df.show()\n",
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------+---------------------------------------+\n",
            "|to_date(DOB, dd/MMM/yyyy HH:mm:ss)|to_timestamp(DOB, dd/MMM/yyyy HH:mm:ss)|\n",
            "+----------------------------------+---------------------------------------+\n",
            "|                        2019-12-25|                    2019-12-25 13:30:00|\n",
            "+----------------------------------+---------------------------------------+\n",
            "\n",
            "root\n",
            " |-- to_date(DOB, dd/MMM/yyyy HH:mm:ss): date (nullable = true)\n",
            " |-- to_timestamp(DOB, dd/MMM/yyyy HH:mm:ss): timestamp (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIPQyQV7-Hz5"
      },
      "source": [
        "**What is 3 days earlier that the oldest date and 3 days later than the most recent date?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUCEwQkZ-I7h",
        "outputId": "82621ccc-0113-4f4d-fb22-1551ab137893"
      },
      "source": [
        "from pyspark.sql.functions import date_add, date_sub\n",
        "# create a dummy dataframe\n",
        "df = spark.createDataFrame([('1990-01-01',),('1995-01-03',),('2021-03-30',)], ['Date'])\n",
        "# find out the required dates\n",
        "df.select(date_add(max(col('Date')),3), date_sub(min(col('Date')),3)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+----------------------+\n",
            "|date_add(max(Date), 3)|date_sub(min(Date), 3)|\n",
            "+----------------------+----------------------+\n",
            "|            2021-04-02|            1989-12-29|\n",
            "+----------------------+----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OZElEvcGOD1"
      },
      "source": [
        "<a id='joins-in-pyspark'></a>\n",
        "## Joins in PySpark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJBC7r3JFyCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65bafd3a-cc37-4a3a-e7ff-9578dd78dd4f"
      },
      "source": [
        "# Create two dataframes\n",
        "cars_df = spark.createDataFrame([[1, 'Car A'],[2, 'Car B'],[3, 'Car C']], [\"id\", \"car_name\"])\n",
        "car_price_df = spark.createDataFrame([[1, 1000],[2, 2000],[3, 3000]], [\"id\", \"car_price\"])\n",
        "cars_df.show()\n",
        "car_price_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------+\n",
            "| id|car_name|\n",
            "+---+--------+\n",
            "|  1|   Car A|\n",
            "|  2|   Car B|\n",
            "|  3|   Car C|\n",
            "+---+--------+\n",
            "\n",
            "+---+---------+\n",
            "| id|car_price|\n",
            "+---+---------+\n",
            "|  1|     1000|\n",
            "|  2|     2000|\n",
            "|  3|     3000|\n",
            "+---+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7Py4EYyKJTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bcd2bed-a2a1-4ef7-dbb5-20d27170ce05"
      },
      "source": [
        "# Executing an inner join so we can see the id, name and price of each car in one row\n",
        "cars_df.join(car_price_df, cars_df.id == car_price_df.id, 'inner').select(cars_df['id'],cars_df['car_name'],car_price_df['car_price']).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------+---------+\n",
            "|id |car_name|car_price|\n",
            "+---+--------+---------+\n",
            "|1  |Car A   |1000     |\n",
            "|3  |Car C   |3000     |\n",
            "|2  |Car B   |2000     |\n",
            "+---+--------+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj0mPaHU5i5n"
      },
      "source": [
        "As you can see, we have done an inner join between two dataframes. The following joins are supported by PySpark:\n",
        "1. inner (default)\n",
        "2. cross\n",
        "3. outer\n",
        "4. full\n",
        "5. full_outer\n",
        "6. left\n",
        "7. left_outer\n",
        "8. right\n",
        "9. right_outer\n",
        "10. left_semi\n",
        "11. left_anti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNPhsx8P2tUH"
      },
      "source": [
        "<a id='spark-sql'></a>\n",
        "## Spark SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHMvBBAh23cw"
      },
      "source": [
        "SQL has been around since the 1970s, and so one can imagine the number of people who made it their bread and butter. As big data came into popularity, the number of professionals with the technical knowledge to deal with it was in shortage. This led to the creation of Spark SQL. To quote the docs:<br>\n",
        ">Spark SQL is a Spark module for structured data processing. Unlike the basic Spark RDD API, the interfaces provided by Spark SQL provide Spark with more information about the structure of both the data and the computation being performed. Internally, Spark SQL uses this extra information to perform extra optimizations.\n",
        "\n",
        "Basically, what you need to know is that Spark SQL is used to execute SQL queries on big data. Spark SQL can also be used to read data from Hive tables and views. Let me explain Spark SQL with an example.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2DaK9-D7QkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3156cd-7629-4021-fe8f-1f8b7980e650"
      },
      "source": [
        "# Load data\n",
        "df = spark.read.csv('cars.csv', header=True, sep=\";\")\n",
        "# Register Temporary Table\n",
        "df.createOrReplaceTempView(\"temp\")\n",
        "# Select all data from temp table\n",
        "spark.sql(\"select * from temp limit 5\").show()\n",
        "# Select count of data in table\n",
        "spark.sql(\"select count(*) as total_count from temp\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "|                 Car| MPG|Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|\n",
            "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "|Chevrolet Chevell...|18.0|        8|       307.0|     130.0| 3504.|        12.0|   70|    US|\n",
            "|   Buick Skylark 320|15.0|        8|       350.0|     165.0| 3693.|        11.5|   70|    US|\n",
            "|  Plymouth Satellite|18.0|        8|       318.0|     150.0| 3436.|        11.0|   70|    US|\n",
            "|       AMC Rebel SST|16.0|        8|       304.0|     150.0| 3433.|        12.0|   70|    US|\n",
            "|         Ford Torino|17.0|        8|       302.0|     140.0| 3449.|        10.5|   70|    US|\n",
            "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "\n",
            "+-----------+\n",
            "|total_count|\n",
            "+-----------+\n",
            "|        406|\n",
            "+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i32WE8j_ec8"
      },
      "source": [
        "As you can see, we registered the dataframe as temporary table and then ran basic SQL queries on it. How amazing is that?!<br>\n",
        "If you are a person who is more comfortable with SQL, then this feature is truly a blessing for you! But this raises a question:\n",
        "> *Should I just keep using Spark SQL all the time?*\n",
        "\n",
        "And the answer is, _**it depends**_.<br>\n",
        "So basically, the different functions acts in differnet ways, and depending upon the type of action you are trying to do, the speed at which it completes execution also differs. But as time progress, this feature is getting better and better, so hopefully the difference should be a small margin. There are plenty of analysis done on this, but nothing has a definite answer yet. You can read this [comparative study done by horton works](https://community.cloudera.com/t5/Community-Articles/Spark-RDDs-vs-DataFrames-vs-SparkSQL/ta-p/246547) or the answer to this [stackoverflow question](https://stackoverflow.com/questions/45430816/writing-sql-vs-using-dataframe-apis-in-spark-sql) if you are still curious about it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x62BiCgBMOtq"
      },
      "source": [
        "<a id='rdd'></a>\n",
        "## RDD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGXK6uEuUKRh"
      },
      "source": [
        "> With map, you define a function and then apply it record by record. Flatmap returns a new RDD by first applying a function to all of the elements in RDDs and then flattening the result. Filter, returns a new RDD. Meaning only the elements that satisfy a condition. With reduce, we are taking neighboring elements and producing a single combined result.\n",
        "For example, let's say you have a set of numbers. You can reduce this to its sum by providing a function that takes as input two values and reduces them to one.\n",
        "\n",
        "Some of the reasons you would use a dataframe over RDD are:\n",
        "1.   It's ability to represnt data as rows and columns. But this also means it can only hold structred and semi-structured data.\n",
        "2.   It allows processing data in different formats (AVRO, CSV, JSON, and storage system HDFS, HIVE tables, MySQL).\n",
        "3. It's superior job Optimization capability.\n",
        "4. DataFrame API is very easy to use.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_WvAgyvR7m6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca36808-b04a-4a45-d628-aeb6b5bab927"
      },
      "source": [
        "cars = spark.sparkContext.textFile('cars.csv')\n",
        "print(cars.first())\n",
        "cars_header = cars.first()\n",
        "cars_rest = cars.filter(lambda line: line!=cars_header)\n",
        "print(cars_rest.first())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Car;MPG;Cylinders;Displacement;Horsepower;Weight;Acceleration;Model;Origin\n",
            "Chevrolet Chevelle Malibu;18.0;8;307.0;130.0;3504.;12.0;70;US\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P65eAFO3Mkdd"
      },
      "source": [
        "**How many cars are there in our csv data?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi03EU0CMSmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2215311f-b291-4659-b2ac-4f3d4491531f"
      },
      "source": [
        "cars_rest.map(lambda line: line.split(\";\")).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "406"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c4bci70MnlQ"
      },
      "source": [
        "**Display the Car name, MPG, Cylinders, Weight and Origin for the cars Originating in Europe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWFpo_WxMnvm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db9ccb02-d380-4b62-8ff8-679ed5e06e11"
      },
      "source": [
        "# Car name is column  0\n",
        "(cars_rest.filter(lambda line: line.split(\";\")[8]=='Europe').\n",
        " map(lambda line: (line.split(\";\")[0],\n",
        "    line.split(\";\")[1],\n",
        "    line.split(\";\")[2],\n",
        "    line.split(\";\")[5],\n",
        "    line.split(\";\")[8])).collect())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Citroen DS-21 Pallas', '0', '4', '3090.', 'Europe'),\n",
              " ('Volkswagen 1131 Deluxe Sedan', '26.0', '4', '1835.', 'Europe'),\n",
              " ('Peugeot 504', '25.0', '4', '2672.', 'Europe'),\n",
              " ('Audi 100 LS', '24.0', '4', '2430.', 'Europe'),\n",
              " ('Saab 99e', '25.0', '4', '2375.', 'Europe'),\n",
              " ('BMW 2002', '26.0', '4', '2234.', 'Europe'),\n",
              " ('Volkswagen Super Beetle 117', '0', '4', '1978.', 'Europe'),\n",
              " ('Opel 1900', '28.0', '4', '2123.', 'Europe'),\n",
              " ('Peugeot 304', '30.0', '4', '2074.', 'Europe'),\n",
              " ('Fiat 124B', '30.0', '4', '2065.', 'Europe'),\n",
              " ('Volkswagen Model 111', '27.0', '4', '1834.', 'Europe'),\n",
              " ('Volkswagen Type 3', '23.0', '4', '2254.', 'Europe'),\n",
              " ('Volvo 145e (sw)', '18.0', '4', '2933.', 'Europe'),\n",
              " ('Volkswagen 411 (sw)', '22.0', '4', '2511.', 'Europe'),\n",
              " ('Peugeot 504 (sw)', '21.0', '4', '2979.', 'Europe'),\n",
              " ('Renault 12 (sw)', '26.0', '4', '2189.', 'Europe'),\n",
              " ('Volkswagen Super Beetle', '26.0', '4', '1950.', 'Europe'),\n",
              " ('Fiat 124 Sport Coupe', '26.0', '4', '2265.', 'Europe'),\n",
              " ('Fiat 128', '29.0', '4', '1867.', 'Europe'),\n",
              " ('Opel Manta', '24.0', '4', '2158.', 'Europe'),\n",
              " ('Audi 100LS', '20.0', '4', '2582.', 'Europe'),\n",
              " ('Volvo 144ea', '19.0', '4', '2868.', 'Europe'),\n",
              " ('Saab 99le', '24.0', '4', '2660.', 'Europe'),\n",
              " ('Audi Fox', '29.0', '4', '2219.', 'Europe'),\n",
              " ('Volkswagen Dasher', '26.0', '4', '1963.', 'Europe'),\n",
              " ('Opel Manta', '26.0', '4', '2300.', 'Europe'),\n",
              " ('Fiat 128', '24.0', '4', '2108.', 'Europe'),\n",
              " ('Fiat 124 TC', '26.0', '4', '2246.', 'Europe'),\n",
              " ('Fiat x1.9', '31.0', '4', '2000.', 'Europe'),\n",
              " ('Volkswagen Dasher', '25.0', '4', '2223.', 'Europe'),\n",
              " ('Volkswagen Rabbit', '29.0', '4', '1937.', 'Europe'),\n",
              " ('Audi 100LS', '23.0', '4', '2694.', 'Europe'),\n",
              " ('Peugeot 504', '23.0', '4', '2957.', 'Europe'),\n",
              " ('Volvo 244DL', '22.0', '4', '2945.', 'Europe'),\n",
              " ('Saab 99LE', '25.0', '4', '2671.', 'Europe'),\n",
              " ('Fiat 131', '28.0', '4', '2464.', 'Europe'),\n",
              " ('Opel 1900', '25.0', '4', '2220.', 'Europe'),\n",
              " ('Renault 12tl', '27.0', '4', '2202.', 'Europe'),\n",
              " ('Volkswagen Rabbit', '29.0', '4', '1937.', 'Europe'),\n",
              " ('Volkswagen Rabbit', '29.5', '4', '1825.', 'Europe'),\n",
              " ('Volvo 245', '20.0', '4', '3150.', 'Europe'),\n",
              " ('Peugeot 504', '19.0', '4', '3270.', 'Europe'),\n",
              " ('Mercedes-Benz 280s', '16.5', '6', '3820.', 'Europe'),\n",
              " ('Renault 5 GTL', '36.0', '4', '1825.', 'Europe'),\n",
              " ('Volkswagen Rabbit Custom', '29.0', '4', '1940.', 'Europe'),\n",
              " ('Volkswagen Dasher', '30.5', '4', '2190.', 'Europe'),\n",
              " ('BMW 320i', '21.5', '4', '2600.', 'Europe'),\n",
              " ('Volkswagen Rabbit Custom Diesel', '43.1', '4', '1985.', 'Europe'),\n",
              " ('Audi 5000', '20.3', '5', '2830.', 'Europe'),\n",
              " ('Volvo 264gl', '17.0', '6', '3140.', 'Europe'),\n",
              " ('Saab 99gle', '21.6', '4', '2795.', 'Europe'),\n",
              " ('Peugeot 604sl', '16.2', '6', '3410.', 'Europe'),\n",
              " ('Volkswagen Scirocco', '31.5', '4', '1990.', 'Europe'),\n",
              " ('Volkswagen Rabbit Custom', '31.9', '4', '1925.', 'Europe'),\n",
              " ('Mercedes Benz 300d', '25.4', '5', '3530.', 'Europe'),\n",
              " ('Peugeot 504', '27.2', '4', '3190.', 'Europe'),\n",
              " ('Fiat Strada Custom', '37.3', '4', '2130.', 'Europe'),\n",
              " ('Volkswagen Rabbit', '41.5', '4', '2144.', 'Europe'),\n",
              " ('Audi 4000', '34.3', '4', '2188.', 'Europe'),\n",
              " ('Volkswagen Rabbit C (Diesel)', '44.3', '4', '2085.', 'Europe'),\n",
              " ('Volkswagen Dasher (diesel)', '43.4', '4', '2335.', 'Europe'),\n",
              " ('Audi 5000s (diesel)', '36.4', '5', '2950.', 'Europe'),\n",
              " ('Mercedes-Benz 240d', '30.0', '4', '3250.', 'Europe'),\n",
              " ('Renault Lecar Deluxe', '40.9', '4', '1835.', 'Europe'),\n",
              " ('Volkswagen Rabbit', '29.8', '4', '1845.', 'Europe'),\n",
              " ('Triumph TR7 Coupe', '35.0', '4', '2500.', 'Europe'),\n",
              " ('Volkswagen Jetta', '33.0', '4', '2190.', 'Europe'),\n",
              " ('Renault 18i', '34.5', '4', '2320.', 'Europe'),\n",
              " ('Peugeot 505s Turbo Diesel', '28.1', '4', '3230.', 'Europe'),\n",
              " ('Saab 900s', '0', '4', '2800.', 'Europe'),\n",
              " ('Volvo Diesel', '30.7', '6', '3160.', 'Europe'),\n",
              " ('Volkswagen Rabbit l', '36.0', '4', '1980.', 'Europe'),\n",
              " ('Volkswagen Pickup', '44.0', '4', '2130.', 'Europe')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYmb5FscMph3"
      },
      "source": [
        "**Display the Car name, MPG, Cylinders, Weight and Origin for the cars Originating in either Europe or Japan**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZcRIX3mMquF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d803b6d-02f3-49dd-ef89-6178292d0217"
      },
      "source": [
        "# Car name is column  0\n",
        "(cars_rest.filter(lambda line: line.split(\";\")[8] in ['Europe','Japan']).\n",
        " map(lambda line: (line.split(\";\")[0],\n",
        "    line.split(\";\")[1],\n",
        "    line.split(\";\")[2],\n",
        "    line.split(\";\")[5],\n",
        "    line.split(\";\")[8])).collect())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Citroen DS-21 Pallas', '0', '4', '3090.', 'Europe'),\n",
              " ('Toyota Corolla Mark ii', '24.0', '4', '2372.', 'Japan'),\n",
              " ('Datsun PL510', '27.0', '4', '2130.', 'Japan'),\n",
              " ('Volkswagen 1131 Deluxe Sedan', '26.0', '4', '1835.', 'Europe'),\n",
              " ('Peugeot 504', '25.0', '4', '2672.', 'Europe'),\n",
              " ('Audi 100 LS', '24.0', '4', '2430.', 'Europe'),\n",
              " ('Saab 99e', '25.0', '4', '2375.', 'Europe'),\n",
              " ('BMW 2002', '26.0', '4', '2234.', 'Europe'),\n",
              " ('Datsun PL510', '27.0', '4', '2130.', 'Japan'),\n",
              " ('Toyota Corolla', '25.0', '4', '2228.', 'Japan'),\n",
              " ('Volkswagen Super Beetle 117', '0', '4', '1978.', 'Europe'),\n",
              " ('Opel 1900', '28.0', '4', '2123.', 'Europe'),\n",
              " ('Peugeot 304', '30.0', '4', '2074.', 'Europe'),\n",
              " ('Fiat 124B', '30.0', '4', '2065.', 'Europe'),\n",
              " ('Toyota Corolla 1200', '31.0', '4', '1773.', 'Japan'),\n",
              " ('Datsun 1200', '35.0', '4', '1613.', 'Japan'),\n",
              " ('Volkswagen Model 111', '27.0', '4', '1834.', 'Europe'),\n",
              " ('Toyota Corolla Hardtop', '24.0', '4', '2278.', 'Japan'),\n",
              " ('Volkswagen Type 3', '23.0', '4', '2254.', 'Europe'),\n",
              " ('Mazda RX2 Coupe', '19.0', '3', '2330.', 'Japan'),\n",
              " ('Volvo 145e (sw)', '18.0', '4', '2933.', 'Europe'),\n",
              " ('Volkswagen 411 (sw)', '22.0', '4', '2511.', 'Europe'),\n",
              " ('Peugeot 504 (sw)', '21.0', '4', '2979.', 'Europe'),\n",
              " ('Renault 12 (sw)', '26.0', '4', '2189.', 'Europe'),\n",
              " ('Datsun 510 (sw)', '28.0', '4', '2288.', 'Japan'),\n",
              " ('Toyota Corolla Mark II (sw)', '23.0', '4', '2506.', 'Japan'),\n",
              " ('Toyota Corolla 1600 (sw)', '27.0', '4', '2100.', 'Japan'),\n",
              " ('Volkswagen Super Beetle', '26.0', '4', '1950.', 'Europe'),\n",
              " ('Toyota Camry', '20.0', '4', '2279.', 'Japan'),\n",
              " ('Datsun 610', '22.0', '4', '2379.', 'Japan'),\n",
              " ('Mazda RX3', '18.0', '3', '2124.', 'Japan'),\n",
              " ('Fiat 124 Sport Coupe', '26.0', '4', '2265.', 'Europe'),\n",
              " ('Fiat 128', '29.0', '4', '1867.', 'Europe'),\n",
              " ('Opel Manta', '24.0', '4', '2158.', 'Europe'),\n",
              " ('Audi 100LS', '20.0', '4', '2582.', 'Europe'),\n",
              " ('Volvo 144ea', '19.0', '4', '2868.', 'Europe'),\n",
              " ('Saab 99le', '24.0', '4', '2660.', 'Europe'),\n",
              " ('Toyota Mark II', '20.0', '6', '2807.', 'Japan'),\n",
              " ('Datsun B210', '31.0', '4', '1950.', 'Japan'),\n",
              " ('Toyota Corolla 1200', '32.0', '4', '1836.', 'Japan'),\n",
              " ('Audi Fox', '29.0', '4', '2219.', 'Europe'),\n",
              " ('Volkswagen Dasher', '26.0', '4', '1963.', 'Europe'),\n",
              " ('Opel Manta', '26.0', '4', '2300.', 'Europe'),\n",
              " ('Toyota Corolla', '31.0', '4', '1649.', 'Japan'),\n",
              " ('Datsun 710', '32.0', '4', '2003.', 'Japan'),\n",
              " ('Fiat 128', '24.0', '4', '2108.', 'Europe'),\n",
              " ('Fiat 124 TC', '26.0', '4', '2246.', 'Europe'),\n",
              " ('Honda Civic', '24.0', '4', '2489.', 'Japan'),\n",
              " ('Subaru', '26.0', '4', '2391.', 'Japan'),\n",
              " ('Fiat x1.9', '31.0', '4', '2000.', 'Europe'),\n",
              " ('Toyota Corolla', '29.0', '4', '2171.', 'Japan'),\n",
              " ('Toyota Corolla', '24.0', '4', '2702.', 'Japan'),\n",
              " ('Volkswagen Dasher', '25.0', '4', '2223.', 'Europe'),\n",
              " ('Datsun 710', '24.0', '4', '2545.', 'Japan'),\n",
              " ('Volkswagen Rabbit', '29.0', '4', '1937.', 'Europe'),\n",
              " ('Audi 100LS', '23.0', '4', '2694.', 'Europe'),\n",
              " ('Peugeot 504', '23.0', '4', '2957.', 'Europe'),\n",
              " ('Volvo 244DL', '22.0', '4', '2945.', 'Europe'),\n",
              " ('Saab 99LE', '25.0', '4', '2671.', 'Europe'),\n",
              " ('Honda Civic CVCC', '33.0', '4', '1795.', 'Japan'),\n",
              " ('Fiat 131', '28.0', '4', '2464.', 'Europe'),\n",
              " ('Opel 1900', '25.0', '4', '2220.', 'Europe'),\n",
              " ('Renault 12tl', '27.0', '4', '2202.', 'Europe'),\n",
              " ('Volkswagen Rabbit', '29.0', '4', '1937.', 'Europe'),\n",
              " ('Honda Civic', '33.0', '4', '1795.', 'Japan'),\n",
              " ('Volkswagen Rabbit', '29.5', '4', '1825.', 'Europe'),\n",
              " ('Datsun B-210', '32.0', '4', '1990.', 'Japan'),\n",
              " ('Toyota Corolla', '28.0', '4', '2155.', 'Japan'),\n",
              " ('Volvo 245', '20.0', '4', '3150.', 'Europe'),\n",
              " ('Peugeot 504', '19.0', '4', '3270.', 'Europe'),\n",
              " ('Toyota Mark II', '19.0', '6', '2930.', 'Japan'),\n",
              " ('Mercedes-Benz 280s', '16.5', '6', '3820.', 'Europe'),\n",
              " ('Honda Accord CVCC', '31.5', '4', '2045.', 'Japan'),\n",
              " ('Renault 5 GTL', '36.0', '4', '1825.', 'Europe'),\n",
              " ('Datsun F-10 Hatchback', '33.5', '4', '1945.', 'Japan'),\n",
              " ('Volkswagen Rabbit Custom', '29.0', '4', '1940.', 'Europe'),\n",
              " ('Toyota Corolla Liftback', '26.0', '4', '2265.', 'Japan'),\n",
              " ('Subaru DL', '30.0', '4', '1985.', 'Japan'),\n",
              " ('Volkswagen Dasher', '30.5', '4', '2190.', 'Europe'),\n",
              " ('Datsun 810', '22.0', '6', '2815.', 'Japan'),\n",
              " ('BMW 320i', '21.5', '4', '2600.', 'Europe'),\n",
              " ('Mazda RX-4', '21.5', '3', '2720.', 'Japan'),\n",
              " ('Volkswagen Rabbit Custom Diesel', '43.1', '4', '1985.', 'Europe'),\n",
              " ('Mazda GLC Deluxe', '32.8', '4', '1985.', 'Japan'),\n",
              " ('Datsun B210 GX', '39.4', '4', '2070.', 'Japan'),\n",
              " ('Honda Civic CVCC', '36.1', '4', '1800.', 'Japan'),\n",
              " ('Toyota Corolla', '27.5', '4', '2560.', 'Japan'),\n",
              " ('Datsun 510', '27.2', '4', '2300.', 'Japan'),\n",
              " ('Toyota Celica GT Liftback', '21.1', '4', '2515.', 'Japan'),\n",
              " ('Datsun 200-SX', '23.9', '4', '2405.', 'Japan'),\n",
              " ('Audi 5000', '20.3', '5', '2830.', 'Europe'),\n",
              " ('Volvo 264gl', '17.0', '6', '3140.', 'Europe'),\n",
              " ('Saab 99gle', '21.6', '4', '2795.', 'Europe'),\n",
              " ('Peugeot 604sl', '16.2', '6', '3410.', 'Europe'),\n",
              " ('Volkswagen Scirocco', '31.5', '4', '1990.', 'Europe'),\n",
              " ('Honda Accord LX', '29.5', '4', '2135.', 'Japan'),\n",
              " ('Volkswagen Rabbit Custom', '31.9', '4', '1925.', 'Europe'),\n",
              " ('Mazda GLC Deluxe', '34.1', '4', '1975.', 'Japan'),\n",
              " ('Mercedes Benz 300d', '25.4', '5', '3530.', 'Europe'),\n",
              " ('Peugeot 504', '27.2', '4', '3190.', 'Europe'),\n",
              " ('Datsun 210', '31.8', '4', '2020.', 'Japan'),\n",
              " ('Fiat Strada Custom', '37.3', '4', '2130.', 'Europe'),\n",
              " ('Volkswagen Rabbit', '41.5', '4', '2144.', 'Europe'),\n",
              " ('Toyota Corolla Tercel', '38.1', '4', '1968.', 'Japan'),\n",
              " ('Datsun 310', '37.2', '4', '2019.', 'Japan'),\n",
              " ('Audi 4000', '34.3', '4', '2188.', 'Europe'),\n",
              " ('Toyota Corolla Liftback', '29.8', '4', '2711.', 'Japan'),\n",
              " ('Mazda 626', '31.3', '4', '2542.', 'Japan'),\n",
              " ('Datsun 510 Hatchback', '37.0', '4', '2434.', 'Japan'),\n",
              " ('Toyota Corolla', '32.2', '4', '2265.', 'Japan'),\n",
              " ('Mazda GLC', '46.6', '4', '2110.', 'Japan'),\n",
              " ('Datsun 210', '40.8', '4', '2110.', 'Japan'),\n",
              " ('Volkswagen Rabbit C (Diesel)', '44.3', '4', '2085.', 'Europe'),\n",
              " ('Volkswagen Dasher (diesel)', '43.4', '4', '2335.', 'Europe'),\n",
              " ('Audi 5000s (diesel)', '36.4', '5', '2950.', 'Europe'),\n",
              " ('Mercedes-Benz 240d', '30.0', '4', '3250.', 'Europe'),\n",
              " ('Honda Civic 1500 gl', '44.6', '4', '1850.', 'Japan'),\n",
              " ('Renault Lecar Deluxe', '40.9', '4', '1835.', 'Europe'),\n",
              " ('Subaru DL', '33.8', '4', '2145.', 'Japan'),\n",
              " ('Volkswagen Rabbit', '29.8', '4', '1845.', 'Europe'),\n",
              " ('Datsun 280-ZX', '32.7', '6', '2910.', 'Japan'),\n",
              " ('Mazda RX-7 GS', '23.7', '3', '2420.', 'Japan'),\n",
              " ('Triumph TR7 Coupe', '35.0', '4', '2500.', 'Europe'),\n",
              " ('Honda Accord', '32.4', '4', '2290.', 'Japan'),\n",
              " ('Toyota Starlet', '39.1', '4', '1755.', 'Japan'),\n",
              " ('Honda Civic 1300', '35.1', '4', '1760.', 'Japan'),\n",
              " ('Subaru', '32.3', '4', '2065.', 'Japan'),\n",
              " ('Datsun 210 MPG', '37.0', '4', '1975.', 'Japan'),\n",
              " ('Toyota Tercel', '37.7', '4', '2050.', 'Japan'),\n",
              " ('Mazda GLC 4', '34.1', '4', '1985.', 'Japan'),\n",
              " ('Volkswagen Jetta', '33.0', '4', '2190.', 'Europe'),\n",
              " ('Renault 18i', '34.5', '4', '2320.', 'Europe'),\n",
              " ('Honda Prelude', '33.7', '4', '2210.', 'Japan'),\n",
              " ('Toyota Corolla', '32.4', '4', '2350.', 'Japan'),\n",
              " ('Datsun 200SX', '32.9', '4', '2615.', 'Japan'),\n",
              " ('Mazda 626', '31.6', '4', '2635.', 'Japan'),\n",
              " ('Peugeot 505s Turbo Diesel', '28.1', '4', '3230.', 'Europe'),\n",
              " ('Saab 900s', '0', '4', '2800.', 'Europe'),\n",
              " ('Volvo Diesel', '30.7', '6', '3160.', 'Europe'),\n",
              " ('Toyota Cressida', '25.4', '6', '2900.', 'Japan'),\n",
              " ('Datsun 810 Maxima', '24.2', '6', '2930.', 'Japan'),\n",
              " ('Volkswagen Rabbit l', '36.0', '4', '1980.', 'Europe'),\n",
              " ('Mazda GLC Custom l', '37.0', '4', '2025.', 'Japan'),\n",
              " ('Mazda GLC Custom', '31.0', '4', '1970.', 'Japan'),\n",
              " ('Nissan Stanza XE', '36.0', '4', '2160.', 'Japan'),\n",
              " ('Honda Accord', '36.0', '4', '2205.', 'Japan'),\n",
              " ('Toyota Corolla', '34.0', '4', '2245', 'Japan'),\n",
              " ('Honda Civic', '38.0', '4', '1965.', 'Japan'),\n",
              " ('Honda Civic (auto)', '32.0', '4', '1965.', 'Japan'),\n",
              " ('Datsun 310 GX', '38.0', '4', '1995.', 'Japan'),\n",
              " ('Toyota Celica GT', '32.0', '4', '2665.', 'Japan'),\n",
              " ('Volkswagen Pickup', '44.0', '4', '2130.', 'Europe')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wn2zXe7TbI3"
      },
      "source": [
        "<a id='user-defined-functions-udf'></a>\n",
        "## User-Defined Functions (UDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0YWspcTRrin"
      },
      "source": [
        "PySpark User-Defined Functions (UDFs) help you convert your python code into a scalable version of itself. It comes in handy more than you can imagine, but beware, as the performance is less when you compare it with pyspark functions. You can view examples of how UDF works [here](https://docs.databricks.com/spark/latest/spark-sql/udf-python.html). What I will give in this section is some theory on how it works, and why it is slower.\n",
        "\n",
        "When you try to run a UDF in PySpark, each executor creates a python process. Data will be serialised and deserialised between each executor and python. This leads to lots of performance impact and overhead on spark jobs, making it less efficent than using spark dataframes. Apart from this, sometimes you might have memory issues while using UDFs. The Python worker consumes huge off-heap memory and so it often leads to memoryOverhead, thereby failing your job. Keeping these in mind, I wouldn't recommend using them, but at the end of the day, your choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv7ODDTQRwVt"
      },
      "source": [
        "<a id='common-questions'></a>\n",
        "# Common Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3crkAQVlxKp"
      },
      "source": [
        "<a id='drop-duplicates'></a>\n",
        "## Drop Duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IHrYEwHmBcc"
      },
      "source": [
        "As mentioned earlier, there are two easy to remove duplicates from a dataframe. We have already seen the usage of distinct under <a href=\"#get-distinct-rows\">Get Distinct Rows</a>  section.\n",
        "I will expalin how to use the `dropDuplicates()` function to achieve the same.\n",
        "\n",
        "> `drop_duplicates()` is an alias for `dropDuplicates()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOuHRAPJmWen",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08dcf7e7-91b3-4e42-b418-e29cafd1d1f6"
      },
      "source": [
        "from pyspark.sql import Row\n",
        "from pyspark.sql import Row\n",
        "mylist = [\n",
        "  {\"name\":'Alice',\"age\":5,\"height\":80},\n",
        "  {\"name\":'Jacob',\"age\":24,\"height\":80},\n",
        "  {\"name\":'Alice',\"age\":5,\"height\":80}\n",
        "]\n",
        "df = spark.createDataFrame(Row(**x) for x in mylist)\n",
        "df.dropDuplicates().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+---+------+\n",
            "| name|age|height|\n",
            "+-----+---+------+\n",
            "|Alice|  5|    80|\n",
            "|Jacob| 24|    80|\n",
            "+-----+---+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMv7A-2Hnmjh"
      },
      "source": [
        "`dropDuplicates()` can also take in an optional parameter called *subset* which helps specify the columns on which the duplicate check needs to be done on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHnFylV1n8to",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d2b333-5770-4287-bb48-775bbc08aad2"
      },
      "source": [
        "df.dropDuplicates(subset=['height']).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+---+------+\n",
            "| name|age|height|\n",
            "+-----+---+------+\n",
            "|Alice|  5|    80|\n",
            "+-----+---+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}